{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DTW_edit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jonnytan555/ML_for_Finance/blob/main/DTW_Trade_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tIDEbbWSXVF"
      },
      "source": [
        "#Trade Proccessing with DTW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgBKyqEbSioK"
      },
      "source": [
        "#Project Plan\n",
        "1. Import packages\n",
        "2. Import pyspark functions\n",
        "3. Import dataset from Kaggle \n",
        "4. Create Spark Session\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROE8xZ2aTP4K"
      },
      "source": [
        "#1. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "851K4KvGG-qx",
        "outputId": "9a79f0ce-0127-40d0-b2ea-8b44816cbb95"
      },
      "source": [
        "!pip install sparkmagic\n",
        "!pip install pyspark\n",
        "!pip install tensorflow\n",
        "from functools import reduce\n",
        "from pyspark import StorageLevel\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from datetime import datetime, timedelta\n",
        "from pyspark.sql import Window, Row, DataFrame"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sparkmagic\n",
            "  Downloading https://files.pythonhosted.org/packages/81/7b/157a9f47e07897584f6e0a9590b0f2dcb66d3efeeff79b7b742c0fee6fce/sparkmagic-0.17.1.tar.gz\n",
            "Collecting hdijupyterutils>=0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/aa/218ba2dbb0318f6b47f4d1d010a3e11caa91d9e3a6ee4a62c4f5676d1a58/hdijupyterutils-0.17.1.tar.gz\n",
            "Collecting autovizwidget>=0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/12/79/2b6fbd50a0b11ae9123c14a8a4f9f6a4823c018699c315a331c62e39888d/autovizwidget-0.17.1.tar.gz\n",
            "Requirement already satisfied: ipython>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (5.5.0)\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 26.2MB/s \n",
            "\u001b[?25hCollecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (2.23.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (4.10.1)\n",
            "Requirement already satisfied: ipywidgets>5.0.0 in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (7.6.3)\n",
            "Requirement already satisfied: notebook>=4.2 in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (5.3.1)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (5.1.1)\n",
            "Collecting requests_kerberos>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/a2/866f2b9a60f75055137b9ad127033e397963b2c4769d4b5fab1c3c7e8be3/requests_kerberos-0.12.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jupyter>=1 in /usr/local/lib/python3.6/dist-packages (from hdijupyterutils>=0.6->sparkmagic) (1.0.0)\n",
            "Requirement already satisfied: plotly>=3 in /usr/local/lib/python3.6/dist-packages (from autovizwidget>=0.6->sparkmagic) (4.4.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (51.3.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (4.3.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.1->sparkmagic) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.1->sparkmagic) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->sparkmagic) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->sparkmagic) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->sparkmagic) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->sparkmagic) (1.24.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->sparkmagic) (5.3.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets>5.0.0->sparkmagic) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>5.0.0->sparkmagic) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>5.0.0->sparkmagic) (5.1.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook>=4.2->sparkmagic) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.2->sparkmagic) (4.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.2->sparkmagic) (2.11.2)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.2->sparkmagic) (0.9.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.2->sparkmagic) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.2->sparkmagic) (1.5.0)\n",
            "Collecting cryptography>=1.3; python_version != \"3.3\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/de/7054df0620b5411ba45480f0261e1fb66a53f3db31b28e3aa52c026e72d9/cryptography-3.3.1-cp36-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 20.7MB/s \n",
            "\u001b[?25hCollecting pykerberos<2.0.0,>=1.1.8; sys_platform != \"win32\"\n",
            "  Downloading https://files.pythonhosted.org/packages/9a/b8/1ec56b6fa8a2e2a81420bd3d90e70b59fc83f6b857fb2c2c37accddc8be3/pykerberos-1.2.1.tar.gz\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter>=1->hdijupyterutils>=0.6->sparkmagic) (5.0.2)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter>=1->hdijupyterutils>=0.6->sparkmagic) (5.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly>=3->autovizwidget>=0.6->sparkmagic) (1.15.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=3->autovizwidget>=0.6->sparkmagic) (1.3.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.2->sparkmagic) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.2->sparkmagic) (0.2.5)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->sparkmagic) (21.0.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>5.0.0->sparkmagic) (2.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=4.2->sparkmagic) (1.1.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (1.4.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (3.2.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.6/dist-packages (from cryptography>=1.3; python_version != \"3.3\"->requests_kerberos>=0.8.0->sparkmagic) (1.14.4)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter>=1->hdijupyterutils>=0.6->sparkmagic) (1.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.2->sparkmagic) (20.8)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.2->sparkmagic) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.12->cryptography>=1.3; python_version != \"3.3\"->requests_kerberos>=0.8.0->sparkmagic) (2.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->notebook>=4.2->sparkmagic) (2.4.7)\n",
            "Building wheels for collected packages: sparkmagic, hdijupyterutils, autovizwidget, pykerberos\n",
            "  Building wheel for sparkmagic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sparkmagic: filename=sparkmagic-0.17.1-cp36-none-any.whl size=60501 sha256=51c09487e05a350e70fbb1ceaed7218879d07de14297aa0fce2ba32cabfdcea6\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/a2/3b/a99eab4d35dbd1c73538e326a1008bf1840249729458a30d47\n",
            "  Building wheel for hdijupyterutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdijupyterutils: filename=hdijupyterutils-0.17.1-cp36-none-any.whl size=7697 sha256=2786560862041361606cfde8d577ce0a4e452d9bb2d79b7b32c1e6275e91332c\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/6a/55/be7fcd1fd20ca73d8acc6d1a1aef41988946066ea13f0ba1e1\n",
            "  Building wheel for autovizwidget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autovizwidget: filename=autovizwidget-0.17.1-cp36-none-any.whl size=14550 sha256=28fef74c27a616e7716a4b31e99bc49f29ecd51dd195cde4f0b6f9d72c299fc7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/d3/c7/bc8004542c72aca15956801f082678477556eed29a9beb27e5\n",
            "  Building wheel for pykerberos (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pykerberos\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for pykerberos\n",
            "Successfully built sparkmagic hdijupyterutils autovizwidget\n",
            "Failed to build pykerberos\n",
            "Installing collected packages: nose, mock, hdijupyterutils, autovizwidget, cryptography, pykerberos, requests-kerberos, sparkmagic\n",
            "    Running setup.py install for pykerberos ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-6ltuew1f/pykerberos/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-6ltuew1f/pykerberos/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-hetqt6yn/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n",
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/26/198fc8c0b98580f617cb03cb298c6056587b8f0447e20fa40c5b634ced77/pyspark-3.0.1.tar.gz (204.2MB)\n",
            "\u001b[K     |████████████████████████████████| 204.2MB 75kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 51.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612242 sha256=93872c4c0484cafc7ecd258cf93da292a402e598b27db10c5a54c9f8c4042604\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/bd/07/031766ca628adec8435bb40f0bd83bb676ce65ff4007f8e73f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.1\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (51.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZW7yd_iHmEu"
      },
      "source": [
        "#2. Import pyspark functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKAK8g4dHham"
      },
      "source": [
        "from pyspark.sql.types import StringType, FloatType\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "#from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\n",
        "from itertools import chain\n",
        "# generate random floating point values\n",
        "from random import seed, random, randint, uniform\n",
        "import pandas as pd\n",
        "\n",
        "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "# tf.config.experimental_connect_to_cluster(tpu)\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "# # instantiate a distribution strategy\n",
        "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAcfokjgHrvd"
      },
      "source": [
        "#3. Import dataset from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO5CZYlHH6Vt"
      },
      "source": [
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYRHBr_ZIMWt"
      },
      "source": [
        "#4. Create Spark session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWjdVIzbIScl"
      },
      "source": [
        "# Appending all the datesets together\n",
        "def UnionAll(dfs):\n",
        "    data = reduce(DataFrame.unionAll,dfs)\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj6pLV54IS2t"
      },
      "source": [
        "# Create a subsequence dataframe based on sequence id and trade date\n",
        "# Using step variable as an incremental value, to create additional chunks of data (sort of like moving window)\n",
        "#Why\n",
        "# DTW compares series vs another series andproduces a similarity score\n",
        "# The aim here is to convert dataframes into a matrices and then these are compared to eachother\n",
        "\n",
        "def create_subsequence_data(feature_data,feature_selection_list,seq_len):\n",
        "    \"\"\"Function \"\"\"\n",
        "    subsequence_dict = {}\n",
        "    smaller_sequence_count=0\n",
        "    raw_total_sequences = 0 \n",
        "    index_reference = 0\n",
        "    step_size = 3\n",
        "    feature_data.sort_values(by=['sequence_id','trade_date'],inplace=True)\n",
        "    for name, chunk in feature_data.groupby(['sequence_id']):\n",
        "        sequence_num = 0\n",
        "        if len(chunk) > seq_len:\n",
        "            i = 0\n",
        "            while i*step_size + seq_len <= len(chunk):\n",
        "                if i==0:\n",
        "                    subsequence_chunk = chunk.iloc[0:i*step_size + seq_len,:]\n",
        "                else:\n",
        "                    subsequence_chunk = chunk.iloc[i*step_size:step_size+seq_len, :]\n",
        "                subsequence_chunk['sequence_id'] = index_reference\n",
        "                subsequence_chunk.sort_values(by=['trade_date'],inplace=True);subsequence_chunk.reset_index(inplace=True)\n",
        "                subsequence_chunk = subsequence_chunk[['trade_date','sequence_id'] + feature_selection_list]\n",
        "                subsequence_dict[index_reference] = subsequence_chunk\n",
        "                sequence_num +=1\n",
        "                index_reference+=1\n",
        "                i+=1\n",
        "            else:\n",
        "                if len(chunk) > 5:\n",
        "                    smaller_sequence_count +=1\n",
        "                    small_chunk = chunk.copy()\n",
        "                    small_chunk['sequence_id'] = index_reference\n",
        "                    small_chunk.sort_values(by=['trade_date'],inplace=True)\n",
        "                    small_chunk = small_chunk[['trade_date','sequence_id',]+feature_selection_list]\n",
        "                    subsequence_dict[index_reference] = small_chunk\n",
        "                    sequence_num +=1\n",
        "                    index_reference+=1\n",
        "            raw_total_sequences+=1\n",
        "        if subsequence_dict:\n",
        "            subsequence_array = pd.concat(subsequence_dict,axis=0)\n",
        "        else:\n",
        "            subsequence_array = pd.DataFrame(columns = ['trade_date','sequence_id'] + [x for x in feature_selection_list])\n",
        "    return subsequence_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msDGadlsIZON"
      },
      "source": [
        "# This function is to create a matrix of equal length (see seq_len which was 100 in our case)\n",
        "# Use interpolation and the \n",
        "\n",
        "def interpolate_subsequence(subsequence_dataset,feature_selection_list,seq_len):\n",
        "    subsequence_dict = {}\n",
        "    subsequence_dataset.drop(['tradeId', 'Date'], axis = 1)\n",
        "    for subsequence_id in subsequence_dataset['sequence_id'].drop_duplicates():\n",
        "        chunk = subsequence_dataset[subsequence_dataset['sequence_id'] == subsequence_id]\n",
        "        if len(chunk) < seq_len:\n",
        "            chunk_interpolated = pd.DataFrame(index = [x for x in range(seq_len)])\n",
        "            chunk_interpolated['sequence_id'] = subsequence_id               \n",
        "            chunk_interpolated['trade_data'] = chunk['trade_date'].drop_duplicates()[0]\n",
        "#             chunk_interpolated['trader'] = chunk['trader'].drop_duplicates()[0]   \n",
        " \n",
        "            #Interpolate all continuous valued variables using a Cubic Hermite Spline\n",
        "            for feature in feature_selection_list: #select all continuous valued variables\n",
        "                original_feature_data = pd.DataFrame(chunk[feature]).reset_index(drop = True)            \n",
        "                #Create the required length df by creating an index the same length as the original data but that is sampled at a higher rate\n",
        "                temp_df = pd.DataFrame(data = {feature:np.nan, 'interpolated_indicator': 1}, index = [(x*(len(chunk)-1)/seq_len) for x in range(seq_len)])\n",
        "                temp_df_concat = pd.concat([original_feature_data, temp_df], axis = 0, sort = True).sort_index(axis = 0)\n",
        "                #Interpolate data points using monotone cubic interpolation -\n",
        "                    #Preserves the shape of the time series, monotonicity ensures that new local minima/maxima are not introduced\n",
        "                temp_df_concat[feature] = temp_df_concat[feature].interpolate(method = 'slinear')\n",
        "                chunk_interpolated[feature] = temp_df_concat[feature][temp_df_concat['interpolated_indicator'] == 1].reset_index(drop = True)  \n",
        "                \n",
        "            subsequence_dict[subsequence_id] = chunk_interpolated\n",
        "        else:\n",
        "            subsequence_dict[subsequence_id] = chunk\n",
        "    if subsequence_dict:       \n",
        "        subsequence_array = pd.concat(subsequence_dict.values(), axis = 0)\n",
        "    else:\n",
        "        subsequence_array = pd.DataFrame(columns  = ['sequence_id', 'trade_date', 'trader'] + feature_selection_list)\n",
        "    return subsequence_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEIxiyTJi_zD"
      },
      "source": [
        "def spark_create_subseq_dataset(feature_data, feature_selection_list, seq_len):\n",
        "    \"\"\"Generates a dataframe by subseq_id with sequences of data.\n",
        "    These are to be converted to numpy arrays and then dumped into \n",
        "    multivariate dtw algo.\"\"\"\n",
        "    \n",
        "    subsequence_dict={}\n",
        "    smaller_seq_count=0\n",
        "    raw_total_sequences=0\n",
        "    index_reference=0\n",
        "    #Number to increment data by\n",
        "    step_size=3\n",
        "    #Create list of subseq_ids to filter by \n",
        "    print(\"starting sequencing\")\n",
        "    sids = [i[0] for i in spark.sql(\"SELECT DISTINCT sequence_id FROM ScaledTable\").collect()]\n",
        "    feature_data = feature_data.withColumn('id',monotonically_increasing_id())\n",
        "    feature_data.createOrReplaceTempView('ST')\n",
        "    #Filter to dataset required, using SQL -> Catalyst engine more efficient\n",
        "    for sid in sids:\n",
        "        sequence_num=0\n",
        "        sql_query = \"SELECT * FROM ST WHERE sequence_id=\"+\"'\"+str(sid)+\"'\"\n",
        "#         feature_data = feature_data.filter(col('sequence_id')=sid) \n",
        "        chunk = spark.sql(sql_query)\n",
        "        chunk.createOrReplaceTempView(\"subseq\")\n",
        "        print(\"created subseq table\")\n",
        "        if chunk.count()>seq_len:\n",
        "            i=0\n",
        "            while i*step_size + seq_len <= chunk.count():\n",
        "                if i==0:\n",
        "                    step_query=\"SELECT * FROM subseq WHERE id BETWEEN \"+\"'0'\"+\"AND \"+\"'\"+str((i*step_size)+seq_len)+\"'\"\n",
        "                    subsequence_chunk = spark.sql(step_query)\n",
        "                    print(\"creating first sequence...\")\n",
        "                else:\n",
        "                    step_query=\"SELECT * FROM subseq WHERE id BETWEEN \"+\"'\"+str(i)+\"'\"+\"AND\"+\"'\"+str((i*step_size)+seq_len)+\"'\"\n",
        "                    print(f\"creating sequence number: {i}\")\n",
        "                subsequence_chunk = spark.sql(step_query)\n",
        "                subsequence_chunk = subsequence_chunk.withColumn('subsequence_id',lit(index_reference))\n",
        "                subsequence_chunk=subsequence_chunk.orderBy('trade_date')\n",
        "                cols = ['trade_date','subsequence_id']+feature_selection_list\n",
        "                subsequence_chunk = subsequence_chunk.select(cols)\n",
        "                subsequence_dict[index_reference]=subsequence_chunk\n",
        "                sequence_num+=1\n",
        "                index_reference+=1\n",
        "                i+=1\n",
        "        else:\n",
        "            if chunk.count()>5:\n",
        "                print(\"sequence is smaller so create small seq\")\n",
        "                smaller_sequence_count+=1\n",
        "                small_chunk = chunk\n",
        "                small_chunk.withColumn('sub_subsequence_id',lit(index_reference))\n",
        "                small_chunk.orderBy('trade_date')\n",
        "                s_cols = ['trade_date','sub_subsequence_id']+feature_selection_list\n",
        "                small_chunk = small_chunk.select(s_cols)\n",
        "                subsequence_dict[index_reference] = small_chunk\n",
        "                sequence_num +=1\n",
        "                index_reference+=1\n",
        "            raw_total_sequences+=1\n",
        "    if subsequence_dict:\n",
        "        subsequence_array = pd.concat(subsequence_dict,axis=0)\n",
        "    else:\n",
        "        subsequence_array = pd.DataFrame(columns = ['trade_date','sequence_id'] + [x for x in feature_selection_list])\n",
        "    return subsequence_dict\n",
        "\n",
        "\n",
        "# df = spark.read.csv('/kaggle/input/forex-eurusd-dataset/dataset01_eurusd4h.csv', inferSchema=True,header=True)\n",
        "\n",
        "#Write this data to kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geGqKFh-jERd",
        "outputId": "67f2b5ce-b16f-4bf2-cba9-36c953034854"
      },
      "source": [
        "import string\n",
        "import random\n",
        "#Create random_string for tradeId\n",
        "def str_gen(length):\n",
        "    stringlist=[]\n",
        "    num = []\n",
        "    letters = string.ascii_letters\n",
        "    for i in range(length):\n",
        "        stringlist.append(random.choice(letters))\n",
        "        num.append(str(randint(0,9)))\n",
        "    word = ''.join(stringlist)\n",
        "    num = ''.join(num)\n",
        "    word = word+'-'+num[:2]\n",
        "    return word\n",
        "\n",
        "s_dt = datetime(2020, 10, 1)-timedelta(hours=17912)\n",
        "end_dt = datetime(2020,10,1)\n",
        "step = timedelta(seconds=randint(30,150))\n",
        "dts = []\n",
        "while s_dt<=end_dt:\n",
        "    dts.append(s_dt.strftime('%Y-%m-%d %H:%M:%S'))\n",
        "    s_dt+=step\n",
        "# volume = [randint(1000,10000000) for num in range(df.count())]\n",
        "#Seed the number for random generator\n",
        "seed(1)\n",
        "#Generate example dataset\n",
        "base_dict = {}\n",
        "for num in range(1,len(dts)):\n",
        "    base_dict[num] = {'participation_rate':random.random(),\n",
        "                      'Date':dts[num],\n",
        "                      'Volume':randint(1000,10000000)*(randint(0,9)+randint(0,9)),\n",
        "                     'Strike':uniform(0.9875,1.12345),\n",
        "                     'tradeId': str_gen(7)\n",
        "                     }\n",
        "    if num % 10000==0:\n",
        "        print(f\"{num} rows created\")\n",
        "    else:\n",
        "        continue\n",
        "    \n",
        "data_as_rows = [Row(**{'row_id': k, **v}) for k,v in base_dict.items()]\n",
        "\n",
        "from pyspark.sql.types import StructType, StructField, StringType\n",
        "#Define schema to prevent ValueError\n",
        "# schema = StructType([StructField(\"foo\", StringType(), True), StructFie])\n",
        "schema = 'row_id INTEGER, participation_rate STRING, Date STRING, Volume INTEGER, Strike DOUBLE, tradeId STRING'\n",
        "b = spark.createDataFrame(data_as_rows,schema=schema)\n",
        "# b.to_csv('testdata.csv')\n",
        "# b = spark.read.csv('./testdata.csv/*.csv',header=True)\n",
        "#Create monotonically increasing ids\n",
        "# df = df.withColumn('row_id',row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
        "# Join dfs\n",
        "b = b.withColumn('CCYPAIR',lit('EURUSD'))\n",
        "b = b.withColumn('trade_date',to_date(col('Date')))\n",
        "#Create window\n",
        "#Then denserank, we are assuming working with one traders worth of data\n",
        "subspec = Window.partitionBy('CCYPAIR').orderBy('trade_date')\n",
        "b = b.withColumn('sequence_id',dense_rank().over(subspec))\n",
        "#Scale dataset\n",
        "features = b.columns\n",
        "assemblers = [VectorAssembler(inputCols=[col], outputCol=col+\"_vec\") for col in features]\n",
        "scalers = [MinMaxScaler(inputCol=col+\"_vec\",outputCol=col+\"_scaled\") for col in features]\n",
        "#Convert all columns to float\n",
        "float_df = b.select(*(col(c).cast(\"float\").alias(c) for c in b.columns)).fillna(0)\n",
        "\n",
        "pipeline = Pipeline(stages=assemblers+scalers)\n",
        "model = pipeline.fit(float_df)\n",
        "scaled_df =model.transform(float_df)\n",
        "#Only select scaled columns\n",
        "scaledData = scaled_df.select([col for col in scaled_df.columns if '_scaled' in col])\n",
        "first_element=udf((lambda x:x[0]),FloatType())\n",
        "scaledData=scaledData.select([first_element(col) for col in scaledData.columns])\n",
        "#Rename columns\n",
        "r_scaled_df = reduce(lambda scaledData,idx: scaledData.withColumnRenamed(scaledData.columns[idx],features[idx]),range(len(scaledData.columns)),float_df)\n",
        "\n",
        "#Merge datasets to bring back non float data\n",
        "drop_cols = ['Date','trade_date','CCYPAIR']\n",
        "#Drop string cols\n",
        "r_scaled_df = reduce(DataFrame.drop,drop_cols,r_scaled_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000 rows created\n",
            "20000 rows created\n",
            "30000 rows created\n",
            "40000 rows created\n",
            "50000 rows created\n",
            "60000 rows created\n",
            "70000 rows created\n",
            "80000 rows created\n",
            "90000 rows created\n",
            "100000 rows created\n",
            "110000 rows created\n",
            "120000 rows created\n",
            "130000 rows created\n",
            "140000 rows created\n",
            "150000 rows created\n",
            "160000 rows created\n",
            "170000 rows created\n",
            "180000 rows created\n",
            "190000 rows created\n",
            "200000 rows created\n",
            "210000 rows created\n",
            "220000 rows created\n",
            "230000 rows created\n",
            "240000 rows created\n",
            "250000 rows created\n",
            "260000 rows created\n",
            "270000 rows created\n",
            "280000 rows created\n",
            "290000 rows created\n",
            "300000 rows created\n",
            "310000 rows created\n",
            "320000 rows created\n",
            "330000 rows created\n",
            "340000 rows created\n",
            "350000 rows created\n",
            "360000 rows created\n",
            "370000 rows created\n",
            "380000 rows created\n",
            "390000 rows created\n",
            "400000 rows created\n",
            "410000 rows created\n",
            "420000 rows created\n",
            "430000 rows created\n",
            "440000 rows created\n",
            "450000 rows created\n",
            "460000 rows created\n",
            "470000 rows created\n",
            "480000 rows created\n",
            "490000 rows created\n",
            "500000 rows created\n",
            "510000 rows created\n",
            "520000 rows created\n",
            "530000 rows created\n",
            "540000 rows created\n",
            "550000 rows created\n",
            "560000 rows created\n",
            "570000 rows created\n",
            "580000 rows created\n",
            "590000 rows created\n",
            "600000 rows created\n",
            "610000 rows created\n",
            "620000 rows created\n",
            "630000 rows created\n",
            "640000 rows created\n",
            "650000 rows created\n",
            "660000 rows created\n",
            "670000 rows created\n",
            "680000 rows created\n",
            "690000 rows created\n",
            "700000 rows created\n",
            "710000 rows created\n",
            "720000 rows created\n",
            "730000 rows created\n",
            "740000 rows created\n",
            "750000 rows created\n",
            "760000 rows created\n",
            "770000 rows created\n",
            "780000 rows created\n",
            "790000 rows created\n",
            "800000 rows created\n",
            "810000 rows created\n",
            "820000 rows created\n",
            "830000 rows created\n",
            "840000 rows created\n",
            "850000 rows created\n",
            "860000 rows created\n",
            "870000 rows created\n",
            "880000 rows created\n",
            "890000 rows created\n",
            "900000 rows created\n",
            "910000 rows created\n",
            "920000 rows created\n",
            "930000 rows created\n",
            "940000 rows created\n",
            "950000 rows created\n",
            "960000 rows created\n",
            "970000 rows created\n",
            "980000 rows created\n",
            "990000 rows created\n",
            "1000000 rows created\n",
            "1010000 rows created\n",
            "1020000 rows created\n",
            "1030000 rows created\n",
            "1040000 rows created\n",
            "1050000 rows created\n",
            "1060000 rows created\n",
            "1070000 rows created\n",
            "1080000 rows created\n",
            "1090000 rows created\n",
            "1100000 rows created\n",
            "1110000 rows created\n",
            "1120000 rows created\n",
            "1130000 rows created\n",
            "1140000 rows created\n",
            "1150000 rows created\n",
            "1160000 rows created\n",
            "1170000 rows created\n",
            "1180000 rows created\n",
            "1190000 rows created\n",
            "1200000 rows created\n",
            "1210000 rows created\n",
            "1220000 rows created\n",
            "1230000 rows created\n",
            "1240000 rows created\n",
            "1250000 rows created\n",
            "1260000 rows created\n",
            "1270000 rows created\n",
            "1280000 rows created\n",
            "1290000 rows created\n",
            "1300000 rows created\n",
            "1310000 rows created\n",
            "1320000 rows created\n",
            "1330000 rows created\n",
            "1340000 rows created\n",
            "1350000 rows created\n",
            "1360000 rows created\n",
            "1370000 rows created\n",
            "1380000 rows created\n",
            "1390000 rows created\n",
            "1400000 rows created\n",
            "1410000 rows created\n",
            "1420000 rows created\n",
            "1430000 rows created\n",
            "1440000 rows created\n",
            "1450000 rows created\n",
            "1460000 rows created\n",
            "1470000 rows created\n",
            "1480000 rows created\n",
            "1490000 rows created\n",
            "1500000 rows created\n",
            "1510000 rows created\n",
            "1520000 rows created\n",
            "1530000 rows created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT7unMICjJ5F"
      },
      "source": [
        "def interpolate_subsequence(subsequence_dataset,feature_selection_list,seq_len):\n",
        "    subsequence_dict = {}\n",
        "    subsequence_dataset.drop(['tradeId', 'Date'], axis = 1)\n",
        "    for subsequence_id in subsequence_dataset['sequence_id'].drop_duplicates():\n",
        "        chunk = subsequence_dataset[subsequence_dataset['sequence_id'] == subsequence_id]\n",
        "        if len(chunk) < seq_len:\n",
        "            chunk_interpolated = pd.DataFrame(index = [x for x in range(seq_len)])\n",
        "            chunk_interpolated['sequence_id'] = subsequence_id               \n",
        "            chunk_interpolated['trade_date'] = chunk['trade_date'].drop_duplicates()\n",
        "#             chunk_interpolated['trader'] = chunk['trader'].drop_duplicates()[0]   \n",
        " \n",
        "            #Interpolate all continuous valued variables using a Cubic Hermite Spline\n",
        "            for feature in feature_selection_list: #select all continuous valued variables\n",
        "                original_feature_data = pd.DataFrame(chunk[feature]).reset_index(drop = True)            \n",
        "                #Create the required length df by creating an index the same length as the original data but that is sampled at a higher rate\n",
        "                temp_df = pd.DataFrame(data = {feature:np.nan, 'interpolated_indicator': 1}, index = [(x*(len(chunk)-1)/seq_len) for x in range(seq_len)])\n",
        "                temp_df_concat = pd.concat([original_feature_data, temp_df], axis = 0, sort = True).sort_index(axis = 0)\n",
        "                #Interpolate data points using monotone cubic interpolation -\n",
        "                    #Preserves the shape of the time series, monotonicity ensures that new local minima/maxima are not introduced\n",
        "                temp_df_concat[feature] = temp_df_concat[feature].interpolate(method = 'slinear')\n",
        "                chunk_interpolated[feature] = temp_df_concat[feature][temp_df_concat['interpolated_indicator'] == 1].reset_index(drop = True)  \n",
        "                \n",
        "            subsequence_dict[subsequence_id] = chunk_interpolated\n",
        "        else:\n",
        "            subsequence_dict[subsequence_id] = chunk\n",
        "    if subsequence_dict:       \n",
        "        subsequence_array = pd.concat(subsequence_dict.values(), axis = 0)\n",
        "    else:\n",
        "        subsequence_array = pd.DataFrame(columns  = ['sequence_id', 'trade_date', 'trader'] + feature_selection_list)\n",
        "    return subsequence_array\n",
        "\n",
        "final_df = r_scaled_df.join(b.select('row_id','CCYPAIR','trade_date','Date','tradeId'),'row_id',how='inner').drop(r_scaled_df.tradeId)\n",
        "#Run subsequencing on scaled_Df\n",
        "#Generate subsequence data\n",
        "subseq_window = Window.partitionBy('sequence_id').orderBy('row_id')\n",
        "final_df = final_df.withColumn('subseq_id',dense_rank().over(subseq_window))\n",
        "p_df = final_df.toPandas()\n",
        "#Interpolate data\n",
        "interp_df = interpolate_subsequence(p_df,features,100)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o05H9jebjMzL",
        "outputId": "b9b60982-f5d7-4967-c19f-11a62448cba2"
      },
      "source": [
        "#Installing dependencies for Rpy2\n",
        "import subprocess\n",
        "subprocess.run('conda install -c conda-forge r-base', shell=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args='conda install -c conda-forge r-base', returncode=127)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy-DQ5ydjQOL",
        "outputId": "3bf16a5d-fd33-4e55-db04-c8ea3b096491"
      },
      "source": [
        "# using numba to speed up function\n",
        "# from numba import jit\n",
        "!pip3 install rpy2\n",
        "!pip install tslearn\n",
        "# os.environ\n",
        "import time\n",
        "\n",
        "def trade_dict_gen(df):\n",
        "    start_time = time.perf_counter()\n",
        "    trade_dict = {}\n",
        "    #Filter to sequence_id\n",
        "    ids = [i for i in df['sequence_id'].drop_duplicates()]\n",
        "    #Drop all data and only keep continuous variables\n",
        "    cont_df = df.drop(columns=['row_id','CCYPAIR','trade_date','Date','tradeId','subseq_id'])\n",
        "    for i in ids:\n",
        "        #Converts df into numpy array\n",
        "        trade_dict[i] = cont_df[cont_df.sequence_id == i].values\n",
        "    print(f\"Time elapsed is {time.perf_counter() - start_time}\")\n",
        "    return trade_dict\n",
        "\n",
        "trade_dict = trade_dict_gen(interp_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rpy2 in /usr/local/lib/python3.6/dist-packages (3.2.7)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from rpy2) (2018.9)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.6/dist-packages (from rpy2) (1.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from rpy2) (2.11.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from rpy2) (3.6.4)\n",
            "Requirement already satisfied: cffi>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from rpy2) (1.14.4)\n",
            "Requirement already satisfied: simplegeneric in /usr/local/lib/python3.6/dist-packages (from rpy2) (0.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->rpy2) (1.1.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->rpy2) (20.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->rpy2) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->rpy2) (1.15.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->rpy2) (1.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->rpy2) (51.3.3)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->rpy2) (1.10.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->rpy2) (8.6.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.13.1->rpy2) (2.20)\n",
            "Collecting tslearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/ad/1872c9f7006663e3672116104f811a573a3af5f12b13ccc2a9865baa0ced/tslearn-0.5.0.5-cp36-cp36m-manylinux2010_x86_64.whl (786kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 19.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from tslearn) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tslearn) (1.19.5)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from tslearn) (0.29.21)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from tslearn) (0.51.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from tslearn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from tslearn) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->tslearn) (51.3.3)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.6/dist-packages (from numba->tslearn) (0.34.0)\n",
            "Installing collected packages: tslearn\n",
            "Successfully installed tslearn-0.5.0.5\n",
            "Time elapsed is 2.031384595000077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UqlNZKUJKkL",
        "outputId": "aa227131-062e-483a-81e2-f3244c7ac9f1"
      },
      "source": [
        "# !python -m rpy2.situation\n",
        "import numpy as np\n",
        "import rpy2.robjects as robjects\n",
        "import rpy2.robjects.numpy2ri\n",
        "rpy2.robjects.numpy2ri.activate()\n",
        "from rpy2.robjects.packages import importr\n",
        "utils = robjects.packages.importr(\"utils\")\n",
        "package_name = \"dtw\"\n",
        "utils.install_packages(package_name)\n",
        "\n",
        "R = robjects.r\n",
        "\n",
        "DTW = importr('dtw')\n",
        "\n",
        "def DTW(s1,s2,window):\n",
        "    R = rpy2.robjects.r\n",
        "    DTW = importr('dtw')\n",
        "    R.dtw = SignatureTranslatedFunction(R.dtw,\n",
        "                        init_prm_translate={'window_size': 'window.size'})\n",
        "    rt,ct=s1.shape\n",
        "    rq,cq = s2.shape\n",
        "    templateR=R.matrix(s1,nrow=rt,ncol=ct)\n",
        "    queryR=R.matrix(s2,nrow=rq,ncol=cq)\n",
        "    alignment = R.dtw(templateR,queryR,keep=True, step_pattern=R.rabinerJuangStepPattern(4,\"c\"),open_begin=True,open_end=True)\n",
        "    dist = alignment.rx('distance')[0][0]\n",
        "    return dist\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R[write to console]: Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "R[write to console]: also installing the dependency ‘proxy’\n",
            "\n",
            "\n",
            "R[write to console]: trying URL 'https://cran.rstudio.com/src/contrib/proxy_0.4-24.tar.gz'\n",
            "\n",
            "R[write to console]: Content type 'application/x-gzip'\n",
            "R[write to console]:  length 115932 bytes (113 KB)\n",
            "\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: \n",
            "\n",
            "R[write to console]: downloaded 113 KB\n",
            "\n",
            "\n",
            "R[write to console]: trying URL 'https://cran.rstudio.com/src/contrib/dtw_1.22-3.tar.gz'\n",
            "\n",
            "R[write to console]: Content type 'application/x-gzip'\n",
            "R[write to console]:  length 882684 bytes (861 KB)\n",
            "\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: =\n",
            "R[write to console]: \n",
            "\n",
            "R[write to console]: downloaded 861 KB\n",
            "\n",
            "\n",
            "R[write to console]: \n",
            "\n",
            "R[write to console]: \n",
            "R[write to console]: The downloaded source packages are in\n",
            "\t‘/tmp/Rtmp5sexLm/downloaded_packages’\n",
            "R[write to console]: \n",
            "R[write to console]: \n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1thJNfpJHRL",
        "outputId": "8491ca88-e375-4ae9-ee13-53c6ac38c809"
      },
      "source": [
        "from tslearn import metrics\n",
        "# from numba import jit\n",
        "# @jit\n",
        "def compute_manipulation_scoresv2(t_dict):\n",
        "#     for each series compare to all other series then average it\n",
        "    \n",
        "    #create a list of all other \n",
        "    #Compare to all other sequences\n",
        "    seq_ids = [i for i in t_dict.keys()]\n",
        "    print('Function started')\n",
        "    start_time = time.perf_counter()\n",
        "    for num in range(1,len(t_dict)):\n",
        "        print(f\"Comparing sequence number: {num}\")\n",
        "        df_list=[seq for seq in seq_ids]\n",
        "        del df_list[num]\n",
        "        for idx in df_list:\n",
        "            dtw_dists = []\n",
        "            dtw_dists.append(metrics.dtw(t_dict[num],t_dict[idx]))\n",
        "            t_dict[num]=np.mean(dtw_dists)\n",
        "    print(f\"Time elapsed is {time.perf_counter() - start_time}\")\n",
        "    return t_dict\n",
        "\n",
        "dist_scores = compute_manipulation_scoresv2(trade_dict)\n",
        "\n",
        "# Map values to dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Function started\n",
            "Comparing sequence number: 1\n",
            "Comparing sequence number: 2\n",
            "Comparing sequence number: 3\n",
            "Comparing sequence number: 4\n",
            "Comparing sequence number: 5\n",
            "Comparing sequence number: 6\n",
            "Comparing sequence number: 7\n",
            "Comparing sequence number: 8\n",
            "Comparing sequence number: 9\n",
            "Comparing sequence number: 10\n",
            "Comparing sequence number: 11\n",
            "Comparing sequence number: 12\n",
            "Comparing sequence number: 13\n",
            "Comparing sequence number: 14\n",
            "Comparing sequence number: 15\n",
            "Comparing sequence number: 16\n",
            "Comparing sequence number: 17\n",
            "Comparing sequence number: 18\n",
            "Comparing sequence number: 19\n",
            "Comparing sequence number: 20\n",
            "Comparing sequence number: 21\n",
            "Comparing sequence number: 22\n",
            "Comparing sequence number: 23\n",
            "Comparing sequence number: 24\n",
            "Comparing sequence number: 25\n",
            "Comparing sequence number: 26\n",
            "Comparing sequence number: 27\n",
            "Comparing sequence number: 28\n",
            "Comparing sequence number: 29\n",
            "Comparing sequence number: 30\n",
            "Comparing sequence number: 31\n",
            "Comparing sequence number: 32\n",
            "Comparing sequence number: 33\n",
            "Comparing sequence number: 34\n",
            "Comparing sequence number: 35\n",
            "Comparing sequence number: 36\n",
            "Comparing sequence number: 37\n",
            "Comparing sequence number: 38\n",
            "Comparing sequence number: 39\n",
            "Comparing sequence number: 40\n",
            "Comparing sequence number: 41\n",
            "Comparing sequence number: 42\n",
            "Comparing sequence number: 43\n",
            "Comparing sequence number: 44\n",
            "Comparing sequence number: 45\n",
            "Comparing sequence number: 46\n",
            "Comparing sequence number: 47\n",
            "Comparing sequence number: 48\n",
            "Comparing sequence number: 49\n",
            "Comparing sequence number: 50\n",
            "Comparing sequence number: 51\n",
            "Comparing sequence number: 52\n",
            "Comparing sequence number: 53\n",
            "Comparing sequence number: 54\n",
            "Comparing sequence number: 55\n",
            "Comparing sequence number: 56\n",
            "Comparing sequence number: 57\n",
            "Comparing sequence number: 58\n",
            "Comparing sequence number: 59\n",
            "Comparing sequence number: 60\n",
            "Comparing sequence number: 61\n",
            "Comparing sequence number: 62\n",
            "Comparing sequence number: 63\n",
            "Comparing sequence number: 64\n",
            "Comparing sequence number: 65\n",
            "Comparing sequence number: 66\n",
            "Comparing sequence number: 67\n",
            "Comparing sequence number: 68\n",
            "Comparing sequence number: 69\n",
            "Comparing sequence number: 70\n",
            "Comparing sequence number: 71\n",
            "Comparing sequence number: 72\n",
            "Comparing sequence number: 73\n",
            "Comparing sequence number: 74\n",
            "Comparing sequence number: 75\n",
            "Comparing sequence number: 76\n",
            "Comparing sequence number: 77\n",
            "Comparing sequence number: 78\n",
            "Comparing sequence number: 79\n",
            "Comparing sequence number: 80\n",
            "Comparing sequence number: 81\n",
            "Comparing sequence number: 82\n",
            "Comparing sequence number: 83\n",
            "Comparing sequence number: 84\n",
            "Comparing sequence number: 85\n",
            "Comparing sequence number: 86\n",
            "Comparing sequence number: 87\n",
            "Comparing sequence number: 88\n",
            "Comparing sequence number: 89\n",
            "Comparing sequence number: 90\n",
            "Comparing sequence number: 91\n",
            "Comparing sequence number: 92\n",
            "Comparing sequence number: 93\n",
            "Comparing sequence number: 94\n",
            "Comparing sequence number: 95\n",
            "Comparing sequence number: 96\n",
            "Comparing sequence number: 97\n",
            "Comparing sequence number: 98\n",
            "Comparing sequence number: 99\n",
            "Comparing sequence number: 100\n",
            "Comparing sequence number: 101\n",
            "Comparing sequence number: 102\n",
            "Comparing sequence number: 103\n",
            "Comparing sequence number: 104\n",
            "Comparing sequence number: 105\n",
            "Comparing sequence number: 106\n",
            "Comparing sequence number: 107\n",
            "Comparing sequence number: 108\n",
            "Comparing sequence number: 109\n",
            "Comparing sequence number: 110\n",
            "Comparing sequence number: 111\n",
            "Comparing sequence number: 112\n",
            "Comparing sequence number: 113\n",
            "Comparing sequence number: 114\n",
            "Comparing sequence number: 115\n",
            "Comparing sequence number: 116\n",
            "Comparing sequence number: 117\n",
            "Comparing sequence number: 118\n",
            "Comparing sequence number: 119\n",
            "Comparing sequence number: 120\n",
            "Comparing sequence number: 121\n",
            "Comparing sequence number: 122\n",
            "Comparing sequence number: 123\n",
            "Comparing sequence number: 124\n",
            "Comparing sequence number: 125\n",
            "Comparing sequence number: 126\n",
            "Comparing sequence number: 127\n",
            "Comparing sequence number: 128\n",
            "Comparing sequence number: 129\n",
            "Comparing sequence number: 130\n",
            "Comparing sequence number: 131\n",
            "Comparing sequence number: 132\n",
            "Comparing sequence number: 133\n",
            "Comparing sequence number: 134\n",
            "Comparing sequence number: 135\n",
            "Comparing sequence number: 136\n",
            "Comparing sequence number: 137\n",
            "Comparing sequence number: 138\n",
            "Comparing sequence number: 139\n",
            "Comparing sequence number: 140\n",
            "Comparing sequence number: 141\n",
            "Comparing sequence number: 142\n",
            "Comparing sequence number: 143\n",
            "Comparing sequence number: 144\n",
            "Comparing sequence number: 145\n",
            "Comparing sequence number: 146\n",
            "Comparing sequence number: 147\n",
            "Comparing sequence number: 148\n",
            "Comparing sequence number: 149\n",
            "Comparing sequence number: 150\n",
            "Comparing sequence number: 151\n",
            "Comparing sequence number: 152\n",
            "Comparing sequence number: 153\n",
            "Comparing sequence number: 154\n",
            "Comparing sequence number: 155\n",
            "Comparing sequence number: 156\n",
            "Comparing sequence number: 157\n",
            "Comparing sequence number: 158\n",
            "Comparing sequence number: 159\n",
            "Comparing sequence number: 160\n",
            "Comparing sequence number: 161\n",
            "Comparing sequence number: 162\n",
            "Comparing sequence number: 163\n",
            "Comparing sequence number: 164\n",
            "Comparing sequence number: 165\n",
            "Comparing sequence number: 166\n",
            "Comparing sequence number: 167\n",
            "Comparing sequence number: 168\n",
            "Comparing sequence number: 169\n",
            "Comparing sequence number: 170\n",
            "Comparing sequence number: 171\n",
            "Comparing sequence number: 172\n",
            "Comparing sequence number: 173\n",
            "Comparing sequence number: 174\n",
            "Comparing sequence number: 175\n",
            "Comparing sequence number: 176\n",
            "Comparing sequence number: 177\n",
            "Comparing sequence number: 178\n",
            "Comparing sequence number: 179\n",
            "Comparing sequence number: 180\n",
            "Comparing sequence number: 181\n",
            "Comparing sequence number: 182\n",
            "Comparing sequence number: 183\n",
            "Comparing sequence number: 184\n",
            "Comparing sequence number: 185\n",
            "Comparing sequence number: 186\n",
            "Comparing sequence number: 187\n",
            "Comparing sequence number: 188\n",
            "Comparing sequence number: 189\n",
            "Comparing sequence number: 190\n",
            "Comparing sequence number: 191\n",
            "Comparing sequence number: 192\n",
            "Comparing sequence number: 193\n",
            "Comparing sequence number: 194\n",
            "Comparing sequence number: 195\n",
            "Comparing sequence number: 196\n",
            "Comparing sequence number: 197\n",
            "Comparing sequence number: 198\n",
            "Comparing sequence number: 199\n",
            "Comparing sequence number: 200\n",
            "Comparing sequence number: 201\n",
            "Comparing sequence number: 202\n",
            "Comparing sequence number: 203\n",
            "Comparing sequence number: 204\n",
            "Comparing sequence number: 205\n",
            "Comparing sequence number: 206\n",
            "Comparing sequence number: 207\n",
            "Comparing sequence number: 208\n",
            "Comparing sequence number: 209\n",
            "Comparing sequence number: 210\n",
            "Comparing sequence number: 211\n",
            "Comparing sequence number: 212\n",
            "Comparing sequence number: 213\n",
            "Comparing sequence number: 214\n",
            "Comparing sequence number: 215\n",
            "Comparing sequence number: 216\n",
            "Comparing sequence number: 217\n",
            "Comparing sequence number: 218\n",
            "Comparing sequence number: 219\n",
            "Comparing sequence number: 220\n",
            "Comparing sequence number: 221\n",
            "Comparing sequence number: 222\n",
            "Comparing sequence number: 223\n",
            "Comparing sequence number: 224\n",
            "Comparing sequence number: 225\n",
            "Comparing sequence number: 226\n",
            "Comparing sequence number: 227\n",
            "Comparing sequence number: 228\n",
            "Comparing sequence number: 229\n",
            "Comparing sequence number: 230\n",
            "Comparing sequence number: 231\n",
            "Comparing sequence number: 232\n",
            "Comparing sequence number: 233\n",
            "Comparing sequence number: 234\n",
            "Comparing sequence number: 235\n",
            "Comparing sequence number: 236\n",
            "Comparing sequence number: 237\n",
            "Comparing sequence number: 238\n",
            "Comparing sequence number: 239\n",
            "Comparing sequence number: 240\n",
            "Comparing sequence number: 241\n",
            "Comparing sequence number: 242\n",
            "Comparing sequence number: 243\n",
            "Comparing sequence number: 244\n",
            "Comparing sequence number: 245\n",
            "Comparing sequence number: 246\n",
            "Comparing sequence number: 247\n",
            "Comparing sequence number: 248\n",
            "Comparing sequence number: 249\n",
            "Comparing sequence number: 250\n",
            "Comparing sequence number: 251\n",
            "Comparing sequence number: 252\n",
            "Comparing sequence number: 253\n",
            "Comparing sequence number: 254\n",
            "Comparing sequence number: 255\n",
            "Comparing sequence number: 256\n",
            "Comparing sequence number: 257\n",
            "Comparing sequence number: 258\n",
            "Comparing sequence number: 259\n",
            "Comparing sequence number: 260\n",
            "Comparing sequence number: 261\n",
            "Comparing sequence number: 262\n",
            "Comparing sequence number: 263\n",
            "Comparing sequence number: 264\n",
            "Comparing sequence number: 265\n",
            "Comparing sequence number: 266\n",
            "Comparing sequence number: 267\n",
            "Comparing sequence number: 268\n",
            "Comparing sequence number: 269\n",
            "Comparing sequence number: 270\n",
            "Comparing sequence number: 271\n",
            "Comparing sequence number: 272\n",
            "Comparing sequence number: 273\n",
            "Comparing sequence number: 274\n",
            "Comparing sequence number: 275\n",
            "Comparing sequence number: 276\n",
            "Comparing sequence number: 277\n",
            "Comparing sequence number: 278\n",
            "Comparing sequence number: 279\n",
            "Comparing sequence number: 280\n",
            "Comparing sequence number: 281\n",
            "Comparing sequence number: 282\n",
            "Comparing sequence number: 283\n",
            "Comparing sequence number: 284\n",
            "Comparing sequence number: 285\n",
            "Comparing sequence number: 286\n",
            "Comparing sequence number: 287\n",
            "Comparing sequence number: 288\n",
            "Comparing sequence number: 289\n",
            "Comparing sequence number: 290\n",
            "Comparing sequence number: 291\n",
            "Comparing sequence number: 292\n",
            "Comparing sequence number: 293\n",
            "Comparing sequence number: 294\n",
            "Comparing sequence number: 295\n",
            "Comparing sequence number: 296\n",
            "Comparing sequence number: 297\n",
            "Comparing sequence number: 298\n",
            "Comparing sequence number: 299\n",
            "Comparing sequence number: 300\n",
            "Comparing sequence number: 301\n",
            "Comparing sequence number: 302\n",
            "Comparing sequence number: 303\n",
            "Comparing sequence number: 304\n",
            "Comparing sequence number: 305\n",
            "Comparing sequence number: 306\n",
            "Comparing sequence number: 307\n",
            "Comparing sequence number: 308\n",
            "Comparing sequence number: 309\n",
            "Comparing sequence number: 310\n",
            "Comparing sequence number: 311\n",
            "Comparing sequence number: 312\n",
            "Comparing sequence number: 313\n",
            "Comparing sequence number: 314\n",
            "Comparing sequence number: 315\n",
            "Comparing sequence number: 316\n",
            "Comparing sequence number: 317\n",
            "Comparing sequence number: 318\n",
            "Comparing sequence number: 319\n",
            "Comparing sequence number: 320\n",
            "Comparing sequence number: 321\n",
            "Comparing sequence number: 322\n",
            "Comparing sequence number: 323\n",
            "Comparing sequence number: 324\n",
            "Comparing sequence number: 325\n",
            "Comparing sequence number: 326\n",
            "Comparing sequence number: 327\n",
            "Comparing sequence number: 328\n",
            "Comparing sequence number: 329\n",
            "Comparing sequence number: 330\n",
            "Comparing sequence number: 331\n",
            "Comparing sequence number: 332\n",
            "Comparing sequence number: 333\n",
            "Comparing sequence number: 334\n",
            "Comparing sequence number: 335\n",
            "Comparing sequence number: 336\n",
            "Comparing sequence number: 337\n",
            "Comparing sequence number: 338\n",
            "Comparing sequence number: 339\n",
            "Comparing sequence number: 340\n",
            "Comparing sequence number: 341\n",
            "Comparing sequence number: 342\n",
            "Comparing sequence number: 343\n",
            "Comparing sequence number: 344\n",
            "Comparing sequence number: 345\n",
            "Comparing sequence number: 346\n",
            "Comparing sequence number: 347\n",
            "Comparing sequence number: 348\n",
            "Comparing sequence number: 349\n",
            "Comparing sequence number: 350\n",
            "Comparing sequence number: 351\n",
            "Comparing sequence number: 352\n",
            "Comparing sequence number: 353\n",
            "Comparing sequence number: 354\n",
            "Comparing sequence number: 355\n",
            "Comparing sequence number: 356\n",
            "Comparing sequence number: 357\n",
            "Comparing sequence number: 358\n",
            "Comparing sequence number: 359\n",
            "Comparing sequence number: 360\n",
            "Comparing sequence number: 361\n",
            "Comparing sequence number: 362\n",
            "Comparing sequence number: 363\n",
            "Comparing sequence number: 364\n",
            "Comparing sequence number: 365\n",
            "Comparing sequence number: 366\n",
            "Comparing sequence number: 367\n",
            "Comparing sequence number: 368\n",
            "Comparing sequence number: 369\n",
            "Comparing sequence number: 370\n",
            "Comparing sequence number: 371\n",
            "Comparing sequence number: 372\n",
            "Comparing sequence number: 373\n",
            "Comparing sequence number: 374\n",
            "Comparing sequence number: 375\n",
            "Comparing sequence number: 376\n",
            "Comparing sequence number: 377\n",
            "Comparing sequence number: 378\n",
            "Comparing sequence number: 379\n",
            "Comparing sequence number: 380\n",
            "Comparing sequence number: 381\n",
            "Comparing sequence number: 382\n",
            "Comparing sequence number: 383\n",
            "Comparing sequence number: 384\n",
            "Comparing sequence number: 385\n",
            "Comparing sequence number: 386\n",
            "Comparing sequence number: 387\n",
            "Comparing sequence number: 388\n",
            "Comparing sequence number: 389\n",
            "Comparing sequence number: 390\n",
            "Comparing sequence number: 391\n",
            "Comparing sequence number: 392\n",
            "Comparing sequence number: 393\n",
            "Comparing sequence number: 394\n",
            "Comparing sequence number: 395\n",
            "Comparing sequence number: 396\n",
            "Comparing sequence number: 397\n",
            "Comparing sequence number: 398\n",
            "Comparing sequence number: 399\n",
            "Comparing sequence number: 400\n",
            "Comparing sequence number: 401\n",
            "Comparing sequence number: 402\n",
            "Comparing sequence number: 403\n",
            "Comparing sequence number: 404\n",
            "Comparing sequence number: 405\n",
            "Comparing sequence number: 406\n",
            "Comparing sequence number: 407\n",
            "Comparing sequence number: 408\n",
            "Comparing sequence number: 409\n",
            "Comparing sequence number: 410\n",
            "Comparing sequence number: 411\n",
            "Comparing sequence number: 412\n",
            "Comparing sequence number: 413\n",
            "Comparing sequence number: 414\n",
            "Comparing sequence number: 415\n",
            "Comparing sequence number: 416\n",
            "Comparing sequence number: 417\n",
            "Comparing sequence number: 418\n",
            "Comparing sequence number: 419\n",
            "Comparing sequence number: 420\n",
            "Comparing sequence number: 421\n",
            "Comparing sequence number: 422\n",
            "Comparing sequence number: 423\n",
            "Comparing sequence number: 424\n",
            "Comparing sequence number: 425\n",
            "Comparing sequence number: 426\n",
            "Comparing sequence number: 427\n",
            "Comparing sequence number: 428\n",
            "Comparing sequence number: 429\n",
            "Comparing sequence number: 430\n",
            "Comparing sequence number: 431\n",
            "Comparing sequence number: 432\n",
            "Comparing sequence number: 433\n",
            "Comparing sequence number: 434\n",
            "Comparing sequence number: 435\n",
            "Comparing sequence number: 436\n",
            "Comparing sequence number: 437\n",
            "Comparing sequence number: 438\n",
            "Comparing sequence number: 439\n",
            "Comparing sequence number: 440\n",
            "Comparing sequence number: 441\n",
            "Comparing sequence number: 442\n",
            "Comparing sequence number: 443\n",
            "Comparing sequence number: 444\n",
            "Comparing sequence number: 445\n",
            "Comparing sequence number: 446\n",
            "Comparing sequence number: 447\n",
            "Comparing sequence number: 448\n",
            "Comparing sequence number: 449\n",
            "Comparing sequence number: 450\n",
            "Comparing sequence number: 451\n",
            "Comparing sequence number: 452\n",
            "Comparing sequence number: 453\n",
            "Comparing sequence number: 454\n",
            "Comparing sequence number: 455\n",
            "Comparing sequence number: 456\n",
            "Comparing sequence number: 457\n",
            "Comparing sequence number: 458\n",
            "Comparing sequence number: 459\n",
            "Comparing sequence number: 460\n",
            "Comparing sequence number: 461\n",
            "Comparing sequence number: 462\n",
            "Comparing sequence number: 463\n",
            "Comparing sequence number: 464\n",
            "Comparing sequence number: 465\n",
            "Comparing sequence number: 466\n",
            "Comparing sequence number: 467\n",
            "Comparing sequence number: 468\n",
            "Comparing sequence number: 469\n",
            "Comparing sequence number: 470\n",
            "Comparing sequence number: 471\n",
            "Comparing sequence number: 472\n",
            "Comparing sequence number: 473\n",
            "Comparing sequence number: 474\n",
            "Comparing sequence number: 475\n",
            "Comparing sequence number: 476\n",
            "Comparing sequence number: 477\n",
            "Comparing sequence number: 478\n",
            "Comparing sequence number: 479\n",
            "Comparing sequence number: 480\n",
            "Comparing sequence number: 481\n",
            "Comparing sequence number: 482\n",
            "Comparing sequence number: 483\n",
            "Comparing sequence number: 484\n",
            "Comparing sequence number: 485\n",
            "Comparing sequence number: 486\n",
            "Comparing sequence number: 487\n",
            "Comparing sequence number: 488\n",
            "Comparing sequence number: 489\n",
            "Comparing sequence number: 490\n",
            "Comparing sequence number: 491\n",
            "Comparing sequence number: 492\n",
            "Comparing sequence number: 493\n",
            "Comparing sequence number: 494\n",
            "Comparing sequence number: 495\n",
            "Comparing sequence number: 496\n",
            "Comparing sequence number: 497\n",
            "Comparing sequence number: 498\n",
            "Comparing sequence number: 499\n",
            "Comparing sequence number: 500\n",
            "Comparing sequence number: 501\n",
            "Comparing sequence number: 502\n",
            "Comparing sequence number: 503\n",
            "Comparing sequence number: 504\n",
            "Comparing sequence number: 505\n",
            "Comparing sequence number: 506\n",
            "Comparing sequence number: 507\n",
            "Comparing sequence number: 508\n",
            "Comparing sequence number: 509\n",
            "Comparing sequence number: 510\n",
            "Comparing sequence number: 511\n",
            "Comparing sequence number: 512\n",
            "Comparing sequence number: 513\n",
            "Comparing sequence number: 514\n",
            "Comparing sequence number: 515\n",
            "Comparing sequence number: 516\n",
            "Comparing sequence number: 517\n",
            "Comparing sequence number: 518\n",
            "Comparing sequence number: 519\n",
            "Comparing sequence number: 520\n",
            "Comparing sequence number: 521\n",
            "Comparing sequence number: 522\n",
            "Comparing sequence number: 523\n",
            "Comparing sequence number: 524\n",
            "Comparing sequence number: 525\n",
            "Comparing sequence number: 526\n",
            "Comparing sequence number: 527\n",
            "Comparing sequence number: 528\n",
            "Comparing sequence number: 529\n",
            "Comparing sequence number: 530\n",
            "Comparing sequence number: 531\n",
            "Comparing sequence number: 532\n",
            "Comparing sequence number: 533\n",
            "Comparing sequence number: 534\n",
            "Comparing sequence number: 535\n",
            "Comparing sequence number: 536\n",
            "Comparing sequence number: 537\n",
            "Comparing sequence number: 538\n",
            "Comparing sequence number: 539\n",
            "Comparing sequence number: 540\n",
            "Comparing sequence number: 541\n",
            "Comparing sequence number: 542\n",
            "Comparing sequence number: 543\n",
            "Comparing sequence number: 544\n",
            "Comparing sequence number: 545\n",
            "Comparing sequence number: 546\n",
            "Comparing sequence number: 547\n",
            "Comparing sequence number: 548\n",
            "Comparing sequence number: 549\n",
            "Comparing sequence number: 550\n",
            "Comparing sequence number: 551\n",
            "Comparing sequence number: 552\n",
            "Comparing sequence number: 553\n",
            "Comparing sequence number: 554\n",
            "Comparing sequence number: 555\n",
            "Comparing sequence number: 556\n",
            "Comparing sequence number: 557\n",
            "Comparing sequence number: 558\n",
            "Comparing sequence number: 559\n",
            "Comparing sequence number: 560\n",
            "Comparing sequence number: 561\n",
            "Comparing sequence number: 562\n",
            "Comparing sequence number: 563\n",
            "Comparing sequence number: 564\n",
            "Comparing sequence number: 565\n",
            "Comparing sequence number: 566\n",
            "Comparing sequence number: 567\n",
            "Comparing sequence number: 568\n",
            "Comparing sequence number: 569\n",
            "Comparing sequence number: 570\n",
            "Comparing sequence number: 571\n",
            "Comparing sequence number: 572\n",
            "Comparing sequence number: 573\n",
            "Comparing sequence number: 574\n",
            "Comparing sequence number: 575\n",
            "Comparing sequence number: 576\n",
            "Comparing sequence number: 577\n",
            "Comparing sequence number: 578\n",
            "Comparing sequence number: 579\n",
            "Comparing sequence number: 580\n",
            "Comparing sequence number: 581\n",
            "Comparing sequence number: 582\n",
            "Comparing sequence number: 583\n",
            "Comparing sequence number: 584\n",
            "Comparing sequence number: 585\n",
            "Comparing sequence number: 586\n",
            "Comparing sequence number: 587\n",
            "Comparing sequence number: 588\n",
            "Comparing sequence number: 589\n",
            "Comparing sequence number: 590\n",
            "Comparing sequence number: 591\n",
            "Comparing sequence number: 592\n",
            "Comparing sequence number: 593\n",
            "Comparing sequence number: 594\n",
            "Comparing sequence number: 595\n",
            "Comparing sequence number: 596\n",
            "Comparing sequence number: 597\n",
            "Comparing sequence number: 598\n",
            "Comparing sequence number: 599\n",
            "Comparing sequence number: 600\n",
            "Comparing sequence number: 601\n",
            "Comparing sequence number: 602\n",
            "Comparing sequence number: 603\n",
            "Comparing sequence number: 604\n",
            "Comparing sequence number: 605\n",
            "Comparing sequence number: 606\n",
            "Comparing sequence number: 607\n",
            "Comparing sequence number: 608\n",
            "Comparing sequence number: 609\n",
            "Comparing sequence number: 610\n",
            "Comparing sequence number: 611\n",
            "Comparing sequence number: 612\n",
            "Comparing sequence number: 613\n",
            "Comparing sequence number: 614\n",
            "Comparing sequence number: 615\n",
            "Comparing sequence number: 616\n",
            "Comparing sequence number: 617\n",
            "Comparing sequence number: 618\n",
            "Comparing sequence number: 619\n",
            "Comparing sequence number: 620\n",
            "Comparing sequence number: 621\n",
            "Comparing sequence number: 622\n",
            "Comparing sequence number: 623\n",
            "Comparing sequence number: 624\n",
            "Comparing sequence number: 625\n",
            "Comparing sequence number: 626\n",
            "Comparing sequence number: 627\n",
            "Comparing sequence number: 628\n",
            "Comparing sequence number: 629\n",
            "Comparing sequence number: 630\n",
            "Comparing sequence number: 631\n",
            "Comparing sequence number: 632\n",
            "Comparing sequence number: 633\n",
            "Comparing sequence number: 634\n",
            "Comparing sequence number: 635\n",
            "Comparing sequence number: 636\n",
            "Comparing sequence number: 637\n",
            "Comparing sequence number: 638\n",
            "Comparing sequence number: 639\n",
            "Comparing sequence number: 640\n",
            "Comparing sequence number: 641\n",
            "Comparing sequence number: 642\n",
            "Comparing sequence number: 643\n",
            "Comparing sequence number: 644\n",
            "Comparing sequence number: 645\n",
            "Comparing sequence number: 646\n",
            "Comparing sequence number: 647\n",
            "Comparing sequence number: 648\n",
            "Comparing sequence number: 649\n",
            "Comparing sequence number: 650\n",
            "Comparing sequence number: 651\n",
            "Comparing sequence number: 652\n",
            "Comparing sequence number: 653\n",
            "Comparing sequence number: 654\n",
            "Comparing sequence number: 655\n",
            "Comparing sequence number: 656\n",
            "Comparing sequence number: 657\n",
            "Comparing sequence number: 658\n",
            "Comparing sequence number: 659\n",
            "Comparing sequence number: 660\n",
            "Comparing sequence number: 661\n",
            "Comparing sequence number: 662\n",
            "Comparing sequence number: 663\n",
            "Comparing sequence number: 664\n",
            "Comparing sequence number: 665\n",
            "Comparing sequence number: 666\n",
            "Comparing sequence number: 667\n",
            "Comparing sequence number: 668\n",
            "Comparing sequence number: 669\n",
            "Comparing sequence number: 670\n",
            "Comparing sequence number: 671\n",
            "Comparing sequence number: 672\n",
            "Comparing sequence number: 673\n",
            "Comparing sequence number: 674\n",
            "Comparing sequence number: 675\n",
            "Comparing sequence number: 676\n",
            "Comparing sequence number: 677\n",
            "Comparing sequence number: 678\n",
            "Comparing sequence number: 679\n",
            "Comparing sequence number: 680\n",
            "Comparing sequence number: 681\n",
            "Comparing sequence number: 682\n",
            "Comparing sequence number: 683\n",
            "Comparing sequence number: 684\n",
            "Comparing sequence number: 685\n",
            "Comparing sequence number: 686\n",
            "Comparing sequence number: 687\n",
            "Comparing sequence number: 688\n",
            "Comparing sequence number: 689\n",
            "Comparing sequence number: 690\n",
            "Comparing sequence number: 691\n",
            "Comparing sequence number: 692\n",
            "Comparing sequence number: 693\n",
            "Comparing sequence number: 694\n",
            "Comparing sequence number: 695\n",
            "Comparing sequence number: 696\n",
            "Comparing sequence number: 697\n",
            "Comparing sequence number: 698\n",
            "Comparing sequence number: 699\n",
            "Comparing sequence number: 700\n",
            "Comparing sequence number: 701\n",
            "Comparing sequence number: 702\n",
            "Comparing sequence number: 703\n",
            "Comparing sequence number: 704\n",
            "Comparing sequence number: 705\n",
            "Comparing sequence number: 706\n",
            "Comparing sequence number: 707\n",
            "Comparing sequence number: 708\n",
            "Comparing sequence number: 709\n",
            "Comparing sequence number: 710\n",
            "Comparing sequence number: 711\n",
            "Comparing sequence number: 712\n",
            "Comparing sequence number: 713\n",
            "Comparing sequence number: 714\n",
            "Comparing sequence number: 715\n",
            "Comparing sequence number: 716\n",
            "Comparing sequence number: 717\n",
            "Comparing sequence number: 718\n",
            "Comparing sequence number: 719\n",
            "Comparing sequence number: 720\n",
            "Comparing sequence number: 721\n",
            "Comparing sequence number: 722\n",
            "Comparing sequence number: 723\n",
            "Comparing sequence number: 724\n",
            "Comparing sequence number: 725\n",
            "Comparing sequence number: 726\n",
            "Comparing sequence number: 727\n",
            "Comparing sequence number: 728\n",
            "Comparing sequence number: 729\n",
            "Comparing sequence number: 730\n",
            "Comparing sequence number: 731\n",
            "Comparing sequence number: 732\n",
            "Comparing sequence number: 733\n",
            "Comparing sequence number: 734\n",
            "Comparing sequence number: 735\n",
            "Comparing sequence number: 736\n",
            "Comparing sequence number: 737\n",
            "Comparing sequence number: 738\n",
            "Comparing sequence number: 739\n",
            "Comparing sequence number: 740\n",
            "Comparing sequence number: 741\n",
            "Comparing sequence number: 742\n",
            "Comparing sequence number: 743\n",
            "Comparing sequence number: 744\n",
            "Comparing sequence number: 745\n",
            "Comparing sequence number: 746\n",
            "Time elapsed is 147.94865510800003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc5lvcrQjUF8"
      },
      "source": [
        "dist_scorev2 = {}\n",
        "# if infinity then remove\n",
        "\n",
        "for k,v in dist_scores.items():\n",
        "    dist_scorev2[k] = np.mean(v)\n",
        "    if dist_scorev2[k] > 1E308: \n",
        "        del dist_scorev2[k]\n",
        "    else:\n",
        "        continue \n",
        "\n",
        "#Plot data on histogram\n",
        "# import matplotlib.pyplot as plt\n",
        "# dist_vals = dist_scores.values()\n",
        "# interp_df = interp_df.replace([np.inf, -np.inf],np.nan)\n",
        "\n",
        "# plt.hist(dist_scores.values())\n",
        "# dist_scores.values().dropna()\n",
        "dist_scores = dist_scorev2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "9sb8ZofcjWdP",
        "outputId": "b83d025e-370f-4af0-d289-7d64dfd97167"
      },
      "source": [
        "interp_df['dist_scores'] = interp_df['row_id'].map(dist_scores)\n",
        "display(dist_scores)\n",
        "interp_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{153.0: 26.222090035135967, 575.0: nan, 747.0: 11047252.0}"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>participation_rate</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Strike</th>\n",
              "      <th>sequence_id</th>\n",
              "      <th>CCYPAIR</th>\n",
              "      <th>trade_date</th>\n",
              "      <th>Date</th>\n",
              "      <th>tradeId</th>\n",
              "      <th>subseq_id</th>\n",
              "      <th>dist_scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1465372.0</td>\n",
              "      <td>0.749768</td>\n",
              "      <td>9143890.0</td>\n",
              "      <td>1.048875</td>\n",
              "      <td>714.0</td>\n",
              "      <td>EURUSD</td>\n",
              "      <td>2020-08-28</td>\n",
              "      <td>2020-08-28 00:00:24</td>\n",
              "      <td>UdzjXWY-87</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1465373.0</td>\n",
              "      <td>0.526230</td>\n",
              "      <td>9458456.0</td>\n",
              "      <td>0.995155</td>\n",
              "      <td>714.0</td>\n",
              "      <td>EURUSD</td>\n",
              "      <td>2020-08-28</td>\n",
              "      <td>2020-08-28 00:01:06</td>\n",
              "      <td>qtFZUIk-82</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1465374.0</td>\n",
              "      <td>0.145609</td>\n",
              "      <td>35232840.0</td>\n",
              "      <td>1.077760</td>\n",
              "      <td>714.0</td>\n",
              "      <td>EURUSD</td>\n",
              "      <td>2020-08-28</td>\n",
              "      <td>2020-08-28 00:01:48</td>\n",
              "      <td>GGRBovI-36</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1465375.0</td>\n",
              "      <td>0.399795</td>\n",
              "      <td>20419220.0</td>\n",
              "      <td>1.104236</td>\n",
              "      <td>714.0</td>\n",
              "      <td>EURUSD</td>\n",
              "      <td>2020-08-28</td>\n",
              "      <td>2020-08-28 00:02:30</td>\n",
              "      <td>nNCUXKQ-73</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465376.0</td>\n",
              "      <td>0.392048</td>\n",
              "      <td>27138450.0</td>\n",
              "      <td>1.053306</td>\n",
              "      <td>714.0</td>\n",
              "      <td>EURUSD</td>\n",
              "      <td>2020-08-28</td>\n",
              "      <td>2020-08-28 00:03:12</td>\n",
              "      <td>UBJgcNi-20</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      row_id  participation_rate  ...  subseq_id  dist_scores\n",
              "0  1465372.0            0.749768  ...          1          NaN\n",
              "1  1465373.0            0.526230  ...          2          NaN\n",
              "2  1465374.0            0.145609  ...          3          NaN\n",
              "3  1465375.0            0.399795  ...          4          NaN\n",
              "4  1465376.0            0.392048  ...          5          NaN\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "d-ZTPW-ajZuA",
        "outputId": "603bb926-9288-490b-ea56-832647530409"
      },
      "source": [
        "# dist_vals[dist_vals < 1E308]\n",
        "# Plot the scores available\n",
        "import plotly.express as px\n",
        "# minds = min(dist_scores.values())\n",
        "# maxds = np.max(np.array(dist_scores.values()))\n",
        "# minds = min(dist_scores.keys(), key=(lambda k: dist_scores[k]))\n",
        "# binnums = (maxds-minds)/len(dist_scores)\n",
        "\n",
        "fig = px.histogram(dist_scores.values(),\n",
        "#                    bins=range(maxds,minds,binnums),\n",
        "                   histnorm='probability',\n",
        "                   title='Histogram of DTW Distances',\n",
        "                   labels={'value':'DTW distances'},\n",
        "                  opacity=0.8,\n",
        "                   log_y=True, # represent bars with log scale\n",
        "                   color_discrete_sequence=['indianred'])\n",
        "fig.show()\n",
        "# dist_scorev2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"a9023b83-ab73-4197-beac-ad285511beaa\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"a9023b83-ab73-4197-beac-ad285511beaa\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'a9023b83-ab73-4197-beac-ad285511beaa',\n",
              "                        [],\n",
              "                        {\"barmode\": \"relative\", \"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Histogram of DTW Distances\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"count\"}, \"type\": \"log\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a9023b83-ab73-4197-beac-ad285511beaa');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}