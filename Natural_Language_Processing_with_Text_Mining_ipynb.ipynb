{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Natural_Language_Processing_with_Text_Mining ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jonnytan555/ML_for_Finance/blob/main/Natural_Language_Processing_with_Text_Mining_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq9L3wEkP1Zu"
      },
      "source": [
        "\n",
        "# Text Mining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lK8PsNHRjVq",
        "outputId": "8b2ebc7a-8e16-461d-d7c8-43a650ab714a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RHSwXDzP1Z4"
      },
      "source": [
        "\n",
        "#Main techniques covered in this project\n",
        "\n",
        "Core text processing steps<br>\n",
        "  * Stop word removal<br>\n",
        "  * Stemming<br>\n",
        "  * TF-IDF conversion<br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIdkcSDdP1Z5"
      },
      "source": [
        "#Shakes.txt file can be found in this repository\n",
        "shakes = open('shakes.txt')\n",
        "shakes = shakes.read(5000) "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "j7SRLxF4P1Z7",
        "outputId": "88948fd0-da75-47af-9a00-8446b910e3cb"
      },
      "source": [
        "shakes = shakes.lower()\n",
        "shakes"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the project gutenberg ebook of the complete works of william shakespeare, by\\nwilliam shakespeare\\n\\nthis ebook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.  you may copy it, give it away or\\nre-use it under the terms of the project gutenberg license included\\nwith this ebook or online at www.gutenberg.org\\n\\n** this is a copyrighted project gutenberg ebook, details below **\\n**     please follow the copyright guidelines in this file.     **\\n\\ntitle: the complete works of william shakespeare\\n\\nauthor: william shakespeare\\n\\nposting date: september 1, 2011 [ebook #100]\\nrelease date: january, 1994\\n\\nlanguage: english\\n\\ncharacter set encoding: ascii\\n\\n*** start of this project gutenberg ebook complete works--william shakespeare ***\\n\\n\\n\\n\\nproduced by world library, inc., from their library of the future\\n\\n\\n\\n\\nthis is the 100th etext file presented by project gutenberg, and\\nis presented in cooperation with world library, inc., from their\\nlibrary of the future and shakespeare cdroms.  project gutenberg\\noften releases etexts that are not placed in the public domain!!\\n\\nshakespeare\\n\\n*this etext has certain copyright implications you should read!*\\n\\n<<this electronic version of the complete works of william\\nshakespeare is copyright 1990-1993 by world library, inc., and is\\nprovided by project gutenberg etext of illinois benedictine college\\nwith permission.  electronic and machine readable copies may be\\ndistributed so long as such copies (1) are for your or others\\npersonal use only, and (2) are not distributed or used\\ncommercially.  prohibited commercial distribution includes by any\\nservice that charges for download time or for membership.>>\\n\\n*project gutenberg is proud to cooperate with the world library*\\nin the presentation of the complete works of william shakespeare\\nfor your reading for education and entertainment.  however, this\\nis neither shareware nor public domain. . .and under the library\\nof the future conditions of this presentation. . .no charges may\\nbe made for *any* access to this material.  you are encouraged!!\\nto give it away to anyone you like, but no charges are allowed!!\\n\\n\\n\\n\\n***** small print! for complete shakespeare *****\\n\\nthis electronic version of the complete works of william\\nshakespeare is copyright 1990-1993 by world library, inc.,\\nand is provided by project gutenberg etext of\\nillinois benedictine college with permission.\\n\\nsince unlike many other project gutenberg-tm etexts, this etext\\nis copyright protected, and since the materials and methods you\\nuse will effect the project\\'s reputation, your right to copy and\\ndistribute it is limited by the copyright and other laws, and by\\nthe conditions of this \"small print!\" statement.\\n\\n1.  license\\n\\n  a) you may (and are encouraged) to distribute electronic and\\nmachine readable copies of this etext, so long as such copies\\n(1) are for your or others personal use only, and (2) are not\\ndistributed or used commercially.  prohibited commercial\\ndistribution includes by any service that charges for download\\ntime or for membership.\\n\\n  b) this license is subject to the conditions that you honor\\nthe refund and replacement provisions of this \"small print!\"\\nstatement; and that you distribute exact copies of this etext,\\nincluding this small print statement.  such copies can be\\ncompressed or any proprietary form (including any form resulting\\nfrom word processing or hypertext software), so long as\\n*either*:\\n\\n    (1) the etext, when displayed, is clearly readable, and does\\n  *not* contain characters other than those intended by the\\n  author of the work, although tilde (~), asterisk (*) and\\n  underline (_) characters may be used to convey punctuation\\n  intended by the author, and additional characters may be used\\n  to indicate hypertext links; or\\n\\n    (2) the etext is readily convertible by the reader at no\\n  expense into plain ascii, ebcdic or equivalent form by the\\n  program that displays the etext (as is the case, for instance,\\n  with most word processors); or\\n\\n    (3) you provide or agree to provide on request at no\\n  additional cost, fee or expense, a copy of the etext in plain\\n  ascii.\\n\\n2.  limited warranty; disclaimer of damages\\n\\nthis etext may contain a \"defect\" in the form of incomplete,\\ninaccurate or corrupt data, transcription errors, a copyright or\\nother infringement, a defective or damaged disk, computer virus,\\nor codes that damage or cannot be read by your equipment.  but\\nfor the \"right of replacement or refund\" described below, the\\nproject (and any other party you may receive this etext from as\\na project gutenberg-tm etext) disclaims all liability to you for\\ndamages, costs and expenses, including legal fees, and you have\\nno remedies for negligence or under strict liability, or for\\nbreach of warranty or contract, including but not limited to\\nindirect, consequential, punitive or incidental damages, even if\\nyou give notice of the possibility of such damages.\\n\\nif you discover a defect in this etext within 90 days of receiv-\\ning it, you ca'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "lu2fX4YmP1Z-",
        "outputId": "3ad1676e-0e45-43fa-fdec-bdca0f5aaf82"
      },
      "source": [
        "import re\n",
        "shakes = re.sub( \"[^a-zA-Z]\", \" \", shakes )\n",
        "shakes "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the project gutenberg ebook of the complete works of william shakespeare  by william shakespeare  this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever   you may copy it  give it away or re use it under the terms of the project gutenberg license included with this ebook or online at www gutenberg org     this is a copyrighted project gutenberg ebook  details below           please follow the copyright guidelines in this file          title  the complete works of william shakespeare  author  william shakespeare  posting date  september          ebook       release date  january        language  english  character set encoding  ascii      start of this project gutenberg ebook complete works  william shakespeare         produced by world library  inc   from their library of the future     this is the    th etext file presented by project gutenberg  and is presented in cooperation with world library  inc   from their library of the future and shakespeare cdroms   project gutenberg often releases etexts that are not placed in the public domain    shakespeare   this etext has certain copyright implications you should read      this electronic version of the complete works of william shakespeare is copyright           by world library  inc   and is provided by project gutenberg etext of illinois benedictine college with permission   electronic and machine readable copies may be distributed so long as such copies     are for your or others personal use only  and     are not distributed or used commercially   prohibited commercial distribution includes by any service that charges for download time or for membership      project gutenberg is proud to cooperate with the world library  in the presentation of the complete works of william shakespeare for your reading for education and entertainment   however  this is neither shareware nor public domain     and under the library of the future conditions of this presentation     no charges may be made for  any  access to this material   you are encouraged   to give it away to anyone you like  but no charges are allowed             small print  for complete shakespeare        this electronic version of the complete works of william shakespeare is copyright           by world library  inc   and is provided by project gutenberg etext of illinois benedictine college with permission   since unlike many other project gutenberg tm etexts  this etext is copyright protected  and since the materials and methods you use will effect the project s reputation  your right to copy and distribute it is limited by the copyright and other laws  and by the conditions of this  small print   statement       license    a  you may  and are encouraged  to distribute electronic and machine readable copies of this etext  so long as such copies     are for your or others personal use only  and     are not distributed or used commercially   prohibited commercial distribution includes by any service that charges for download time or for membership     b  this license is subject to the conditions that you honor the refund and replacement provisions of this  small print   statement  and that you distribute exact copies of this etext  including this small print statement   such copies can be compressed or any proprietary form  including any form resulting from word processing or hypertext software   so long as  either            the etext  when displayed  is clearly readable  and does    not  contain characters other than those intended by the   author of the work  although tilde      asterisk     and   underline     characters may be used to convey punctuation   intended by the author  and additional characters may be used   to indicate hypertext links  or          the etext is readily convertible by the reader at no   expense into plain ascii  ebcdic or equivalent form by the   program that displays the etext  as is the case  for instance    with most word processors   or          you provide or agree to provide on request at no   additional cost  fee or expense  a copy of the etext in plain   ascii       limited warranty  disclaimer of damages  this etext may contain a  defect  in the form of incomplete  inaccurate or corrupt data  transcription errors  a copyright or other infringement  a defective or damaged disk  computer virus  or codes that damage or cannot be read by your equipment   but for the  right of replacement or refund  described below  the project  and any other party you may receive this etext from as a project gutenberg tm etext  disclaims all liability to you for damages  costs and expenses  including legal fees  and you have no remedies for negligence or under strict liability  or for breach of warranty or contract  including but not limited to indirect  consequential  punitive or incidental damages  even if you give notice of the possibility of such damages   if you discover a defect in this etext within    days of receiv  ing it  you ca'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wE161-WP1Z_",
        "outputId": "1c0beca9-be25-4844-caf9-8a69c94f7dfc"
      },
      "source": [
        "help(re)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on module re:\n",
            "\n",
            "NAME\n",
            "    re - Support for regular expressions (RE).\n",
            "\n",
            "MODULE REFERENCE\n",
            "    https://docs.python.org/3.7/library/re\n",
            "    \n",
            "    The following documentation is automatically generated from the Python\n",
            "    source files.  It may be incomplete, incorrect or include features that\n",
            "    are considered implementation detail and may vary between Python\n",
            "    implementations.  When in doubt, consult the module reference at the\n",
            "    location listed above.\n",
            "\n",
            "DESCRIPTION\n",
            "    This module provides regular expression matching operations similar to\n",
            "    those found in Perl.  It supports both 8-bit and Unicode strings; both\n",
            "    the pattern and the strings being processed can contain null bytes and\n",
            "    characters outside the US ASCII range.\n",
            "    \n",
            "    Regular expressions can contain both special and ordinary characters.\n",
            "    Most ordinary characters, like \"A\", \"a\", or \"0\", are the simplest\n",
            "    regular expressions; they simply match themselves.  You can\n",
            "    concatenate ordinary characters, so last matches the string 'last'.\n",
            "    \n",
            "    The special characters are:\n",
            "        \".\"      Matches any character except a newline.\n",
            "        \"^\"      Matches the start of the string.\n",
            "        \"$\"      Matches the end of the string or just before the newline at\n",
            "                 the end of the string.\n",
            "        \"*\"      Matches 0 or more (greedy) repetitions of the preceding RE.\n",
            "                 Greedy means that it will match as many repetitions as possible.\n",
            "        \"+\"      Matches 1 or more (greedy) repetitions of the preceding RE.\n",
            "        \"?\"      Matches 0 or 1 (greedy) of the preceding RE.\n",
            "        *?,+?,?? Non-greedy versions of the previous three special characters.\n",
            "        {m,n}    Matches from m to n repetitions of the preceding RE.\n",
            "        {m,n}?   Non-greedy version of the above.\n",
            "        \"\\\\\"     Either escapes special characters or signals a special sequence.\n",
            "        []       Indicates a set of characters.\n",
            "                 A \"^\" as the first character indicates a complementing set.\n",
            "        \"|\"      A|B, creates an RE that will match either A or B.\n",
            "        (...)    Matches the RE inside the parentheses.\n",
            "                 The contents can be retrieved or matched later in the string.\n",
            "        (?aiLmsux) The letters set the corresponding flags defined below.\n",
            "        (?:...)  Non-grouping version of regular parentheses.\n",
            "        (?P<name>...) The substring matched by the group is accessible by name.\n",
            "        (?P=name)     Matches the text matched earlier by the group named name.\n",
            "        (?#...)  A comment; ignored.\n",
            "        (?=...)  Matches if ... matches next, but doesn't consume the string.\n",
            "        (?!...)  Matches if ... doesn't match next.\n",
            "        (?<=...) Matches if preceded by ... (must be fixed length).\n",
            "        (?<!...) Matches if not preceded by ... (must be fixed length).\n",
            "        (?(id/name)yes|no) Matches yes pattern if the group with id/name matched,\n",
            "                           the (optional) no pattern otherwise.\n",
            "    \n",
            "    The special sequences consist of \"\\\\\" and a character from the list\n",
            "    below.  If the ordinary character is not on the list, then the\n",
            "    resulting RE will match the second character.\n",
            "        \\number  Matches the contents of the group of the same number.\n",
            "        \\A       Matches only at the start of the string.\n",
            "        \\Z       Matches only at the end of the string.\n",
            "        \\b       Matches the empty string, but only at the start or end of a word.\n",
            "        \\B       Matches the empty string, but not at the start or end of a word.\n",
            "        \\d       Matches any decimal digit; equivalent to the set [0-9] in\n",
            "                 bytes patterns or string patterns with the ASCII flag.\n",
            "                 In string patterns without the ASCII flag, it will match the whole\n",
            "                 range of Unicode digits.\n",
            "        \\D       Matches any non-digit character; equivalent to [^\\d].\n",
            "        \\s       Matches any whitespace character; equivalent to [ \\t\\n\\r\\f\\v] in\n",
            "                 bytes patterns or string patterns with the ASCII flag.\n",
            "                 In string patterns without the ASCII flag, it will match the whole\n",
            "                 range of Unicode whitespace characters.\n",
            "        \\S       Matches any non-whitespace character; equivalent to [^\\s].\n",
            "        \\w       Matches any alphanumeric character; equivalent to [a-zA-Z0-9_]\n",
            "                 in bytes patterns or string patterns with the ASCII flag.\n",
            "                 In string patterns without the ASCII flag, it will match the\n",
            "                 range of Unicode alphanumeric characters (letters plus digits\n",
            "                 plus underscore).\n",
            "                 With LOCALE, it will match the set [0-9_] plus characters defined\n",
            "                 as letters for the current locale.\n",
            "        \\W       Matches the complement of \\w.\n",
            "        \\\\       Matches a literal backslash.\n",
            "    \n",
            "    This module exports the following functions:\n",
            "        match     Match a regular expression pattern to the beginning of a string.\n",
            "        fullmatch Match a regular expression pattern to all of a string.\n",
            "        search    Search a string for the presence of a pattern.\n",
            "        sub       Substitute occurrences of a pattern found in a string.\n",
            "        subn      Same as sub, but also return the number of substitutions made.\n",
            "        split     Split a string by the occurrences of a pattern.\n",
            "        findall   Find all occurrences of a pattern in a string.\n",
            "        finditer  Return an iterator yielding a Match object for each match.\n",
            "        compile   Compile a pattern into a Pattern object.\n",
            "        purge     Clear the regular expression cache.\n",
            "        escape    Backslash all non-alphanumerics in a string.\n",
            "    \n",
            "    Each function other than purge and escape can take an optional 'flags' argument\n",
            "    consisting of one or more of the following module constants, joined by \"|\".\n",
            "    A, L, and U are mutually exclusive.\n",
            "        A  ASCII       For string patterns, make \\w, \\W, \\b, \\B, \\d, \\D\n",
            "                       match the corresponding ASCII character categories\n",
            "                       (rather than the whole Unicode categories, which is the\n",
            "                       default).\n",
            "                       For bytes patterns, this flag is the only available\n",
            "                       behaviour and needn't be specified.\n",
            "        I  IGNORECASE  Perform case-insensitive matching.\n",
            "        L  LOCALE      Make \\w, \\W, \\b, \\B, dependent on the current locale.\n",
            "        M  MULTILINE   \"^\" matches the beginning of lines (after a newline)\n",
            "                       as well as the string.\n",
            "                       \"$\" matches the end of lines (before a newline) as well\n",
            "                       as the end of the string.\n",
            "        S  DOTALL      \".\" matches any character at all, including the newline.\n",
            "        X  VERBOSE     Ignore whitespace and comments for nicer looking RE's.\n",
            "        U  UNICODE     For compatibility only. Ignored for string patterns (it\n",
            "                       is the default), and forbidden for bytes patterns.\n",
            "    \n",
            "    This module also defines an exception 'error'.\n",
            "\n",
            "CLASSES\n",
            "    builtins.Exception(builtins.BaseException)\n",
            "        error\n",
            "    builtins.object\n",
            "        Match\n",
            "        Pattern\n",
            "    \n",
            "    class Match(builtins.object)\n",
            "     |  The result of re.match() and re.search().\n",
            "     |  Match objects always have a boolean value of True.\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __copy__(self, /)\n",
            "     |  \n",
            "     |  __deepcopy__(self, memo, /)\n",
            "     |  \n",
            "     |  __getitem__(self, key, /)\n",
            "     |      Return self[key].\n",
            "     |  \n",
            "     |  __repr__(self, /)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  end(self, group=0, /)\n",
            "     |      Return index of the end of the substring matched by group.\n",
            "     |  \n",
            "     |  expand(self, /, template)\n",
            "     |      Return the string obtained by doing backslash substitution on the string template, as done by the sub() method.\n",
            "     |  \n",
            "     |  group(...)\n",
            "     |      group([group1, ...]) -> str or tuple.\n",
            "     |      Return subgroup(s) of the match by indices or names.\n",
            "     |      For 0 returns the entire match.\n",
            "     |  \n",
            "     |  groupdict(self, /, default=None)\n",
            "     |      Return a dictionary containing all the named subgroups of the match, keyed by the subgroup name.\n",
            "     |      \n",
            "     |      default\n",
            "     |        Is used for groups that did not participate in the match.\n",
            "     |  \n",
            "     |  groups(self, /, default=None)\n",
            "     |      Return a tuple containing all the subgroups of the match, from 1.\n",
            "     |      \n",
            "     |      default\n",
            "     |        Is used for groups that did not participate in the match.\n",
            "     |  \n",
            "     |  span(self, group=0, /)\n",
            "     |      For match object m, return the 2-tuple (m.start(group), m.end(group)).\n",
            "     |  \n",
            "     |  start(self, group=0, /)\n",
            "     |      Return index of the start of the substring matched by group.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  endpos\n",
            "     |      The index into the string beyond which the RE engine will not go.\n",
            "     |  \n",
            "     |  lastgroup\n",
            "     |      The name of the last matched capturing group.\n",
            "     |  \n",
            "     |  lastindex\n",
            "     |      The integer index of the last matched capturing group.\n",
            "     |  \n",
            "     |  pos\n",
            "     |      The index into the string at which the RE engine started looking for a match.\n",
            "     |  \n",
            "     |  re\n",
            "     |      The regular expression object.\n",
            "     |  \n",
            "     |  regs\n",
            "     |  \n",
            "     |  string\n",
            "     |      The string passed to match() or search().\n",
            "    \n",
            "    class Pattern(builtins.object)\n",
            "     |  Compiled regular expression object.\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __copy__(self, /)\n",
            "     |  \n",
            "     |  __deepcopy__(self, memo, /)\n",
            "     |  \n",
            "     |  __eq__(self, value, /)\n",
            "     |      Return self==value.\n",
            "     |  \n",
            "     |  __ge__(self, value, /)\n",
            "     |      Return self>=value.\n",
            "     |  \n",
            "     |  __gt__(self, value, /)\n",
            "     |      Return self>value.\n",
            "     |  \n",
            "     |  __hash__(self, /)\n",
            "     |      Return hash(self).\n",
            "     |  \n",
            "     |  __le__(self, value, /)\n",
            "     |      Return self<=value.\n",
            "     |  \n",
            "     |  __lt__(self, value, /)\n",
            "     |      Return self<value.\n",
            "     |  \n",
            "     |  __ne__(self, value, /)\n",
            "     |      Return self!=value.\n",
            "     |  \n",
            "     |  __repr__(self, /)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  findall(self, /, string, pos=0, endpos=9223372036854775807)\n",
            "     |      Return a list of all non-overlapping matches of pattern in string.\n",
            "     |  \n",
            "     |  finditer(self, /, string, pos=0, endpos=9223372036854775807)\n",
            "     |      Return an iterator over all non-overlapping matches for the RE pattern in string.\n",
            "     |      \n",
            "     |      For each match, the iterator returns a match object.\n",
            "     |  \n",
            "     |  fullmatch(self, /, string, pos=0, endpos=9223372036854775807)\n",
            "     |      Matches against all of the string.\n",
            "     |  \n",
            "     |  match(self, /, string, pos=0, endpos=9223372036854775807)\n",
            "     |      Matches zero or more characters at the beginning of the string.\n",
            "     |  \n",
            "     |  scanner(self, /, string, pos=0, endpos=9223372036854775807)\n",
            "     |  \n",
            "     |  search(self, /, string, pos=0, endpos=9223372036854775807)\n",
            "     |      Scan through string looking for a match, and return a corresponding match object instance.\n",
            "     |      \n",
            "     |      Return None if no position in the string matches.\n",
            "     |  \n",
            "     |  split(self, /, string, maxsplit=0)\n",
            "     |      Split string by the occurrences of pattern.\n",
            "     |  \n",
            "     |  sub(self, /, repl, string, count=0)\n",
            "     |      Return the string obtained by replacing the leftmost non-overlapping occurrences of pattern in string by the replacement repl.\n",
            "     |  \n",
            "     |  subn(self, /, repl, string, count=0)\n",
            "     |      Return the tuple (new_string, number_of_subs_made) found by replacing the leftmost non-overlapping occurrences of pattern with the replacement repl.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  flags\n",
            "     |      The regex matching flags.\n",
            "     |  \n",
            "     |  groupindex\n",
            "     |      A dictionary mapping group names to group numbers.\n",
            "     |  \n",
            "     |  groups\n",
            "     |      The number of capturing groups in the pattern.\n",
            "     |  \n",
            "     |  pattern\n",
            "     |      The pattern string from which the RE object was compiled.\n",
            "    \n",
            "    class error(builtins.Exception)\n",
            "     |  error(msg, pattern=None, pos=None)\n",
            "     |  \n",
            "     |  Exception raised for invalid regular expressions.\n",
            "     |  \n",
            "     |  Attributes:\n",
            "     |  \n",
            "     |      msg: The unformatted error message\n",
            "     |      pattern: The regular expression pattern\n",
            "     |      pos: The index in the pattern where compilation failed (may be None)\n",
            "     |      lineno: The line corresponding to pos (may be None)\n",
            "     |      colno: The column corresponding to pos (may be None)\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      error\n",
            "     |      builtins.Exception\n",
            "     |      builtins.BaseException\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, msg, pattern=None, pos=None)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object (if defined)\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from builtins.Exception:\n",
            "     |  \n",
            "     |  __new__(*args, **kwargs) from builtins.type\n",
            "     |      Create and return a new object.  See help(type) for accurate signature.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from builtins.BaseException:\n",
            "     |  \n",
            "     |  __delattr__(self, name, /)\n",
            "     |      Implement delattr(self, name).\n",
            "     |  \n",
            "     |  __getattribute__(self, name, /)\n",
            "     |      Return getattr(self, name).\n",
            "     |  \n",
            "     |  __reduce__(...)\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self, /)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  __setattr__(self, name, value, /)\n",
            "     |      Implement setattr(self, name, value).\n",
            "     |  \n",
            "     |  __setstate__(...)\n",
            "     |  \n",
            "     |  __str__(self, /)\n",
            "     |      Return str(self).\n",
            "     |  \n",
            "     |  with_traceback(...)\n",
            "     |      Exception.with_traceback(tb) --\n",
            "     |      set self.__traceback__ to tb and return self.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from builtins.BaseException:\n",
            "     |  \n",
            "     |  __cause__\n",
            "     |      exception cause\n",
            "     |  \n",
            "     |  __context__\n",
            "     |      exception context\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |  \n",
            "     |  __suppress_context__\n",
            "     |  \n",
            "     |  __traceback__\n",
            "     |  \n",
            "     |  args\n",
            "\n",
            "FUNCTIONS\n",
            "    compile(pattern, flags=0)\n",
            "        Compile a regular expression pattern, returning a Pattern object.\n",
            "    \n",
            "    escape(pattern)\n",
            "        Escape special characters in a string.\n",
            "    \n",
            "    findall(pattern, string, flags=0)\n",
            "        Return a list of all non-overlapping matches in the string.\n",
            "        \n",
            "        If one or more capturing groups are present in the pattern, return\n",
            "        a list of groups; this will be a list of tuples if the pattern\n",
            "        has more than one group.\n",
            "        \n",
            "        Empty matches are included in the result.\n",
            "    \n",
            "    finditer(pattern, string, flags=0)\n",
            "        Return an iterator over all non-overlapping matches in the\n",
            "        string.  For each match, the iterator returns a Match object.\n",
            "        \n",
            "        Empty matches are included in the result.\n",
            "    \n",
            "    fullmatch(pattern, string, flags=0)\n",
            "        Try to apply the pattern to all of the string, returning\n",
            "        a Match object, or None if no match was found.\n",
            "    \n",
            "    match(pattern, string, flags=0)\n",
            "        Try to apply the pattern at the start of the string, returning\n",
            "        a Match object, or None if no match was found.\n",
            "    \n",
            "    purge()\n",
            "        Clear the regular expression caches\n",
            "    \n",
            "    search(pattern, string, flags=0)\n",
            "        Scan through string looking for a match to the pattern, returning\n",
            "        a Match object, or None if no match was found.\n",
            "    \n",
            "    split(pattern, string, maxsplit=0, flags=0)\n",
            "        Split the source string by the occurrences of the pattern,\n",
            "        returning a list containing the resulting substrings.  If\n",
            "        capturing parentheses are used in pattern, then the text of all\n",
            "        groups in the pattern are also returned as part of the resulting\n",
            "        list.  If maxsplit is nonzero, at most maxsplit splits occur,\n",
            "        and the remainder of the string is returned as the final element\n",
            "        of the list.\n",
            "    \n",
            "    sub(pattern, repl, string, count=0, flags=0)\n",
            "        Return the string obtained by replacing the leftmost\n",
            "        non-overlapping occurrences of the pattern in string by the\n",
            "        replacement repl.  repl can be either a string or a callable;\n",
            "        if a string, backslash escapes in it are processed.  If it is\n",
            "        a callable, it's passed the Match object and must return\n",
            "        a replacement string to be used.\n",
            "    \n",
            "    subn(pattern, repl, string, count=0, flags=0)\n",
            "        Return a 2-tuple containing (new_string, number).\n",
            "        new_string is the string obtained by replacing the leftmost\n",
            "        non-overlapping occurrences of the pattern in the source\n",
            "        string by the replacement repl.  number is the number of\n",
            "        substitutions that were made. repl can be either a string or a\n",
            "        callable; if a string, backslash escapes in it are processed.\n",
            "        If it is a callable, it's passed the Match object and must\n",
            "        return a replacement string to be used.\n",
            "    \n",
            "    template(pattern, flags=0)\n",
            "        Compile a template pattern, returning a Pattern object\n",
            "\n",
            "DATA\n",
            "    A = <RegexFlag.ASCII: 256>\n",
            "    ASCII = <RegexFlag.ASCII: 256>\n",
            "    DOTALL = <RegexFlag.DOTALL: 16>\n",
            "    I = <RegexFlag.IGNORECASE: 2>\n",
            "    IGNORECASE = <RegexFlag.IGNORECASE: 2>\n",
            "    L = <RegexFlag.LOCALE: 4>\n",
            "    LOCALE = <RegexFlag.LOCALE: 4>\n",
            "    M = <RegexFlag.MULTILINE: 8>\n",
            "    MULTILINE = <RegexFlag.MULTILINE: 8>\n",
            "    S = <RegexFlag.DOTALL: 16>\n",
            "    U = <RegexFlag.UNICODE: 32>\n",
            "    UNICODE = <RegexFlag.UNICODE: 32>\n",
            "    VERBOSE = <RegexFlag.VERBOSE: 64>\n",
            "    X = <RegexFlag.VERBOSE: 64>\n",
            "    __all__ = ['match', 'fullmatch', 'search', 'sub', 'subn', 'split', 'fi...\n",
            "\n",
            "VERSION\n",
            "    2.2.1\n",
            "\n",
            "FILE\n",
            "    /usr/lib/python3.7/re.py\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7YJdou1P1Z_"
      },
      "source": [
        "Import *nltk* and tokenize the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf5j-XLlP1aA",
        "outputId": "9e839d55-dd7e-4f71-a54d-d631037f9a3b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')    # Comment out after installing\n",
        "shakes = nltk.tokenize.word_tokenize(shakes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sKqTu6AP1aB",
        "outputId": "ea11acb7-e91e-4912-9f64-8e2af10d6733"
      },
      "source": [
        "help(nltk)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on package nltk:\n",
            "\n",
            "NAME\n",
            "    nltk\n",
            "\n",
            "DESCRIPTION\n",
            "    The Natural Language Toolkit (NLTK) is an open source Python library\n",
            "    for Natural Language Processing.  A free online book is available.\n",
            "    (If you use the library for academic research, please cite the book.)\n",
            "    \n",
            "    Steven Bird, Ewan Klein, and Edward Loper (2009).\n",
            "    Natural Language Processing with Python.  O'Reilly Media Inc.\n",
            "    http://nltk.org/book\n",
            "    \n",
            "    @version: 3.2.5\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "    app (package)\n",
            "    book\n",
            "    ccg (package)\n",
            "    chat (package)\n",
            "    chunk (package)\n",
            "    classify (package)\n",
            "    cluster (package)\n",
            "    collections\n",
            "    collocations\n",
            "    compat\n",
            "    corpus (package)\n",
            "    data\n",
            "    decorators\n",
            "    downloader\n",
            "    draw (package)\n",
            "    featstruct\n",
            "    grammar\n",
            "    help\n",
            "    inference (package)\n",
            "    internals\n",
            "    jsontags\n",
            "    lazyimport\n",
            "    metrics (package)\n",
            "    misc (package)\n",
            "    parse (package)\n",
            "    probability\n",
            "    sem (package)\n",
            "    sentiment (package)\n",
            "    stem (package)\n",
            "    tag (package)\n",
            "    tbl (package)\n",
            "    test (package)\n",
            "    text\n",
            "    tgrep\n",
            "    tokenize (package)\n",
            "    toolbox\n",
            "    translate (package)\n",
            "    tree\n",
            "    treeprettyprinter\n",
            "    treetransforms\n",
            "    twitter (package)\n",
            "    util\n",
            "    wsd\n",
            "\n",
            "SUBMODULES\n",
            "    agreement\n",
            "    aline\n",
            "    api\n",
            "    association\n",
            "    bleu_score\n",
            "    bllip\n",
            "    boxer\n",
            "    brill\n",
            "    brill_trainer\n",
            "    casual\n",
            "    chart\n",
            "    confusionmatrix\n",
            "    corenlp\n",
            "    crf\n",
            "    decisiontree\n",
            "    dependencygraph\n",
            "    discourse\n",
            "    distance\n",
            "    drt\n",
            "    earleychart\n",
            "    evaluate\n",
            "    featurechart\n",
            "    glue\n",
            "    hmm\n",
            "    hunpos\n",
            "    ibm1\n",
            "    ibm2\n",
            "    ibm3\n",
            "    ibm4\n",
            "    ibm5\n",
            "    ibm_model\n",
            "    isri\n",
            "    lancaster\n",
            "    lfg\n",
            "    linearlogic\n",
            "    logic\n",
            "    mace\n",
            "    malt\n",
            "    mapping\n",
            "    maxent\n",
            "    megam\n",
            "    mwe\n",
            "    naivebayes\n",
            "    nonprojectivedependencyparser\n",
            "    paice\n",
            "    pchart\n",
            "    perceptron\n",
            "    porter\n",
            "    positivenaivebayes\n",
            "    projectivedependencyparser\n",
            "    prover9\n",
            "    punkt\n",
            "    recursivedescent\n",
            "    regexp\n",
            "    relextract\n",
            "    repp\n",
            "    resolution\n",
            "    ribes_score\n",
            "    rslp\n",
            "    rte_classify\n",
            "    scikitlearn\n",
            "    scores\n",
            "    segmentation\n",
            "    senna\n",
            "    sequential\n",
            "    sexpr\n",
            "    shiftreduce\n",
            "    simple\n",
            "    snowball\n",
            "    spearman\n",
            "    stack_decoder\n",
            "    stanford\n",
            "    stanford_segmenter\n",
            "    tableau\n",
            "    tadm\n",
            "    textcat\n",
            "    texttiling\n",
            "    tnt\n",
            "    toktok\n",
            "    transitionparser\n",
            "    treebank\n",
            "    viterbi\n",
            "    weka\n",
            "    wordnet\n",
            "\n",
            "FUNCTIONS\n",
            "    demo()\n",
            "        # override any accidentally imported demo\n",
            "\n",
            "DATA\n",
            "    RUS_PICKLE = 'taggers/averaged_perceptron_tagger_ru/averaged_perceptro...\n",
            "    SLASH = *slash*\n",
            "    TYPE = *type*\n",
            "    __author_email__ = 'stevenbird1@gmail.com'\n",
            "    __classifiers__ = ['Development Status :: 5 - Production/Stable', 'Int...\n",
            "    __copyright__ = 'Copyright (C) 2001-2017 NLTK Project.\\n\\nDistribut......\n",
            "    __keywords__ = ['NLP', 'CL', 'natural language processing', 'computati...\n",
            "    __license__ = 'Apache License, Version 2.0'\n",
            "    __longdescr__ = 'The Natural Language Toolkit (NLTK) is a Python ... p...\n",
            "    __maintainer__ = 'Steven Bird, Edward Loper, Ewan Klein'\n",
            "    __maintainer_email__ = 'stevenbird1@gmail.com'\n",
            "    __url__ = 'http://nltk.org/'\n",
            "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
            "    app = <LazyModule 'nltk.nltk.app'>\n",
            "    chat = <LazyModule 'nltk.nltk.chat'>\n",
            "    class_types = (<class 'type'>,)\n",
            "    corpus = <LazyModule 'nltk.nltk.corpus'>\n",
            "    improved_close_quote_regex = re.compile('([»”’])')\n",
            "    improved_open_quote_regex = re.compile('([«“‘])')\n",
            "    improved_punct_regex = re.compile('([^\\\\.])(\\\\.)([\\\\]\\\\)}>\"\\\\\\'»”’ ]*)...\n",
            "    infile = <_io.TextIOWrapper name='/usr/local/lib/python3....packages/n...\n",
            "    json_tags = {'!nltk.tag.BrillTagger': <class 'nltk.tag.brill.BrillTagg...\n",
            "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
            "    string_types = (<class 'str'>,)\n",
            "    toolbox = <LazyModule 'nltk.nltk.toolbox'>\n",
            "    version_file = '/usr/local/lib/python3.7/dist-packages/nltk/VERSION'\n",
            "    version_info = sys.version_info(major=3, minor=7, micro=10, releaselev...\n",
            "\n",
            "VERSION\n",
            "    3.2.5\n",
            "\n",
            "AUTHOR\n",
            "    Steven Bird, Edward Loper, Ewan Klein\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.7/dist-packages/nltk/__init__.py\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLNxg6wEP1aB"
      },
      "source": [
        "Import the *Counter* library from *collections*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG2Y4eVCP1aC"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8RvltWRP1aC"
      },
      "source": [
        "Display counts of the most common words in the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLa1RfbmP1aC",
        "outputId": "52e4b4c6-c17f-40dd-a4f8-39ac49f7b7bd"
      },
      "source": [
        "Counter(shakes).most_common(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 38),\n",
              " ('of', 31),\n",
              " ('and', 25),\n",
              " ('or', 25),\n",
              " ('this', 22),\n",
              " ('by', 16),\n",
              " ('is', 16),\n",
              " ('for', 16),\n",
              " ('you', 15),\n",
              " ('etext', 15)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sgz9JJFAP1aD"
      },
      "source": [
        "Remove stop words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfFOViJbP1aD",
        "outputId": "40dc06c4-3f50-45c3-bb2e-540e2db2b2ef"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stopwords.words(\"english\")\n",
        "shakes = [w for w in shakes if w not in stopwords.words('english')]\n",
        "Counter(shakes).most_common(10) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('etext', 15),\n",
              " ('project', 13),\n",
              " ('gutenberg', 12),\n",
              " ('shakespeare', 11),\n",
              " ('william', 8),\n",
              " ('may', 8),\n",
              " ('library', 8),\n",
              " ('complete', 7),\n",
              " ('copyright', 7),\n",
              " ('ebook', 6)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtGqihmDP1aE"
      },
      "source": [
        "This function stem's the tokenized words using PorterStemmer and display the 10 most common words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR5CmDuIP1aE",
        "outputId": "0086c2b8-3828-433c-992e-1ed552d29839"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer=PorterStemmer()\n",
        "\n",
        "def stem_tokens(tokens, stemmer):\n",
        "    stemmed = []\n",
        "    for item in tokens:\n",
        "        stemmed.append(stemmer.stem(item))\n",
        "    return stemmed\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stemmed = stem_tokens(shakes, stemmer)\n",
        "count = Counter(stemmed)\n",
        "\n",
        "CommonWords = count.most_common(10)\n",
        "CommonWords"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('etext', 17),\n",
              " ('project', 13),\n",
              " ('gutenberg', 12),\n",
              " ('shakespear', 11),\n",
              " ('use', 9),\n",
              " ('copi', 9),\n",
              " ('william', 8),\n",
              " ('may', 8),\n",
              " ('copyright', 8),\n",
              " ('librari', 8)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e6CNUYeP1aF"
      },
      "source": [
        "To visualize the 10 most common words the list will be converted into a dataframe of common words into a dataframe "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "7aLBjA7qP1aF",
        "outputId": "adad7f8d-aba9-41a8-b7c6-c16cdf5cd974"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(CommonWords, columns=['Word', 'Count'])\n",
        "df.set_index('Word', inplace=True)\n",
        "df"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>etext</th>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>project</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gutenberg</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shakespear</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>use</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>copi</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>william</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>may</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>copyright</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>librari</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Count\n",
              "Word             \n",
              "etext          17\n",
              "project        13\n",
              "gutenberg      12\n",
              "shakespear     11\n",
              "use             9\n",
              "copi            9\n",
              "william         8\n",
              "may             8\n",
              "copyright       8\n",
              "librari         8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK2gjg8VP1aG"
      },
      "source": [
        "Plot the common words as a bar chart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "TmFNMMsdP1aG",
        "outputId": "a8be9cc2-d0db-4d75-83e2-044ce30cf578"
      },
      "source": [
        "df.plot(kind='bar')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa6fd38c310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEHOuAthP1aG"
      },
      "source": [
        "The following code will create a term document matrix of the following syllogism and display a term document\n",
        "\n",
        "\"All mortals die. All men are mortals. All men die.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_nU7QKwP1aH",
        "outputId": "7f212d7f-a7cb-4234-eb25-5a55cc535e68"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "train_set = [\"All mortals die.\", \"All men are mortals.\", \"All men die.\"]\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "transformer = TfidfVectorizer(stop_words=stop_words)\n",
        "\n",
        "transformer.fit_transform(train_set).todense()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.70710678, 0.        , 0.70710678],\n",
              "        [0.        , 0.70710678, 0.70710678],\n",
              "        [0.70710678, 0.70710678, 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajtb5mleP1aH"
      },
      "source": [
        "The *.get_feature_names()* method can be used to to see the words/features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewJFK-zzP1aI",
        "outputId": "def24437-d63f-4dd3-f8fb-f1c378ce8cee"
      },
      "source": [
        "transformer.get_feature_names()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['die', 'men', 'mortals']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x0X84E8P1aI"
      },
      "source": [
        "The *.idf_* attribute can be used to see the inverse document frequency values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u72rO-SkP1aI",
        "outputId": "e4c0ffce-d20f-430f-ec82-1f7298434fd1"
      },
      "source": [
        "idf = transformer.idf_\n",
        "idf"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.28768207, 1.28768207, 1.28768207])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0j4_lTjP1aJ"
      },
      "source": [
        "The *zip()* function to combine the words with their idf values and convert into a list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbPrpnIzP1aJ",
        "outputId": "226f407c-2e45-4392-ad70-bd38f032c342"
      },
      "source": [
        "terms_score  = zip(transformer.get_feature_names(), idf)\n",
        "\n",
        "list(terms_score)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('die', 1.2876820724517808),\n",
              " ('men', 1.2876820724517808),\n",
              " ('mortals', 1.2876820724517808)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}